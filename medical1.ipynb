{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3CNz35ia6Bz3"
   },
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CkRbhMJH6Bz3"
   },
   "source": [
    "### Business Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3PBm5xaj6Bz3"
   },
   "source": [
    "The healthcare industry is rapidly evolving, with professionals facing increasing challenges in managing vast volumes of medical data while delivering accurate and timely diagnoses. The need for quick access to comprehensive, reliable, and up-to-date medical knowledge is critical for improving patient outcomes and ensuring informed decision-making in a fast-paced environment.\n",
    "\n",
    "Healthcare professionals often encounter information overload, struggling to sift through extensive research and data to create accurate diagnoses and treatment plans. This challenge is amplified by the need for efficiency, particularly in emergencies, where time-sensitive decisions are vital. Furthermore, access to trusted, current medical information from renowned manuals and research papers is essential for maintaining high standards of care.\n",
    "\n",
    "To address these challenges, healthcare centers can focus on integrating systems that streamline access to medical knowledge, provide tools to support quick decision-making, and enhance efficiency. Leveraging centralized knowledge platforms and ensuring healthcare providers have continuous access to reliable resources can significantly improve patient care and operational effectiveness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1xDPsqvO6Bz5"
   },
   "source": [
    "**Common Questions to Answer**\n",
    "\n",
    "**1. Diagnostic Assistance**: \"What are the common symptoms and treatments for pulmonary embolism?\"\n",
    "\n",
    "**2. Drug Information**: \"Can you provide the trade names of medications used for treating hypertension?\"\n",
    "\n",
    "**3. Treatment Plans**: \"What are the first-line options and alternatives for managing rheumatoid arthritis?\"\n",
    "\n",
    "**4. Specialty Knowledge**: \"What are the diagnostic steps for suspected endocrine disorders?\"\n",
    "\n",
    "**5. Critical Care Protocols**: \"What is the protocol for managing sepsis in a critical care unit?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CARPKFwm6Bz4"
   },
   "source": [
    "### Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dOElOEXq6Bz4"
   },
   "source": [
    "As an AI specialist, your task is to develop a RAG-based AI solution using renowned medical manuals to address healthcare challenges. The objective is to **understand** issues like information overload, **apply** AI techniques to streamline decision-making, **analyze** its impact on diagnostics and patient outcomes, **evaluate** its potential to standardize care practices, and **create** a functional prototype demonstrating its feasibility and effectiveness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "by9EvAnkSpZf"
   },
   "source": [
    "### Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jw5LievCSru2"
   },
   "source": [
    "The **Merck Manuals** are medical references published by the American pharmaceutical company Merck & Co., that cover a wide range of medical topics, including disorders, tests, diagnoses, and drugs. The manuals have been published since 1899, when Merck & Co. was still a subsidiary of the German company Merck.\n",
    "\n",
    "The manual is provided as a PDF with over 4,000 pages divided into 23 sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lnwETBOE6Bz5"
   },
   "source": [
    "## Installing and Importing Necessary Libraries and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 112474,
     "status": "ok",
     "timestamp": 1747496960650,
     "user": {
      "displayName": "Vidhya Subramanian",
      "userId": "14385231092771658629"
     },
     "user_tz": 300
    },
    "id": "q4GgLhZhUM4V",
    "outputId": "419ef114-48e0-459b-8b5b-e31a1bdb1f9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-cpp-python\n",
      "  Downloading llama_cpp_python-0.3.9.tar.gz (67.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting typing-extensions>=4.5.0 (from llama-cpp-python)\n",
      "  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting numpy>=1.20.0 (from llama-cpp-python)\n",
      "  Downloading numpy-2.2.6-cp313-cp313-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting diskcache>=5.6.1 (from llama-cpp-python)\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting jinja2>=2.11.3 (from llama-cpp-python)\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2>=2.11.3->llama-cpp-python)\n",
      "  Downloading MarkupSafe-3.0.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (4.0 kB)\n",
      "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading numpy-2.2.6-cp313-cp313-macosx_14_0_arm64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
      "Downloading MarkupSafe-3.0.2-cp313-cp313-macosx_11_0_arm64.whl (12 kB)\n",
      "Building wheels for collected packages: llama-cpp-python\n",
      "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.3.9-cp313-cp313-macosx_15_0_arm64.whl size=3503698 sha256=daa0efbef30e75ff74e25180c77260a5fb1935af2415cee7740e361c4cf3106c\n",
      "  Stored in directory: /Users/rudraprakashpandey/Library/Caches/pip/wheels/17/34/ea/37b6118820f9f8ac2a27193fcaa2c5cb95f92ffe2c7f808540\n",
      "Successfully built llama-cpp-python\n",
      "Installing collected packages: typing-extensions, numpy, MarkupSafe, diskcache, jinja2, llama-cpp-python\n",
      "Successfully installed MarkupSafe-3.0.2 diskcache-5.6.3 jinja2-3.1.6 llama-cpp-python-0.3.9 numpy-2.2.6 typing-extensions-4.13.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Installation for GPU llama-cpp-python\n",
    "# uncomment and run the following code in case GPU is being used\n",
    "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 \n",
    "!pip install llama-cpp-python\n",
    "\n",
    "# Installation for CPU llama-cpp-python\n",
    "# uncomment and run the following code in case GPU is not being used\n",
    "# !CMAKE_ARGS=\"-DLLAMA_CUBLAS=off\" FORCE_CMAKE=1 pip install llama-cpp-python==0.1.85 --force-reinstall --no-cache-dir -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 20901,
     "status": "ok",
     "timestamp": 1747496827145,
     "user": {
      "displayName": "Vidhya Subramanian",
      "userId": "14385231092771658629"
     },
     "user_tz": 300
    },
    "id": "5rsoQIOowCTS",
    "outputId": "0496b50f-f784-4119-aeed-02c43bbf5d4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (2.2.6)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (89 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.2.3-cp313-cp313-macosx_11_0_arm64.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.2.3 pytz-2025.2 tzdata-2025.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17270,
     "status": "ok",
     "timestamp": 1747497007782,
     "user": {
      "displayName": "Vidhya Subramanian",
      "userId": "14385231092771658629"
     },
     "user_tz": 300
    },
    "id": "0VOckDVkWGei",
    "outputId": "ba710fd9-e910-4a97-cf83-5da0b198cc45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting huggingface_hub\n",
      "  Downloading huggingface_hub-0.32.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting filelock (from huggingface_hub)\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface_hub)\n",
      "  Downloading fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from huggingface_hub) (25.0)\n",
      "Collecting pyyaml>=5.1 (from huggingface_hub)\n",
      "  Downloading PyYAML-6.0.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting requests (from huggingface_hub)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tqdm>=4.42.1 (from huggingface_hub)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from huggingface_hub) (4.13.2)\n",
      "Collecting hf-xet<2.0.0,>=1.1.2 (from huggingface_hub)\n",
      "  Downloading hf_xet-1.1.2-cp37-abi3-macosx_11_0_arm64.whl.metadata (879 bytes)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->huggingface_hub)\n",
      "  Downloading charset_normalizer-3.4.2-cp313-cp313-macosx_10_13_universal2.whl.metadata (35 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->huggingface_hub)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->huggingface_hub)\n",
      "  Downloading urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->huggingface_hub)\n",
      "  Downloading certifi-2025.4.26-py3-none-any.whl.metadata (2.5 kB)\n",
      "Downloading huggingface_hub-0.32.0-py3-none-any.whl (509 kB)\n",
      "Downloading fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
      "Downloading hf_xet-1.1.2-cp37-abi3-macosx_11_0_arm64.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading PyYAML-6.0.2-cp313-cp313-macosx_11_0_arm64.whl (171 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
      "Downloading charset_normalizer-3.4.2-cp313-cp313-macosx_10_13_universal2.whl (199 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
      "Installing collected packages: urllib3, tqdm, pyyaml, idna, hf-xet, fsspec, filelock, charset-normalizer, certifi, requests, huggingface_hub\n",
      "Successfully installed certifi-2025.4.26 charset-normalizer-3.4.2 filelock-3.18.0 fsspec-2025.5.1 hf-xet-1.1.2 huggingface_hub-0.32.0 idna-3.10 pyyaml-6.0.2 requests-2.32.3 tqdm-4.67.1 urllib3-2.4.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.9.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken)\n",
      "  Downloading regex-2024.11.6-cp313-cp313-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken) (2025.4.26)\n",
      "Downloading tiktoken-0.9.0-cp313-cp313-macosx_11_0_arm64.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.11.6-cp313-cp313-macosx_11_0_arm64.whl (284 kB)\n",
      "Installing collected packages: regex, tiktoken\n",
      "Successfully installed regex-2024.11.6 tiktoken-0.9.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting pymupdf\n",
      "  Downloading pymupdf-1.26.0-cp39-abi3-macosx_11_0_arm64.whl.metadata (3.4 kB)\n",
      "Downloading pymupdf-1.26.0-cp39-abi3-macosx_11_0_arm64.whl (22.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.4/22.4 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pymupdf\n",
      "Successfully installed pymupdf-1.26.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.3.25-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.58 (from langchain)\n",
      "  Downloading langchain_core-0.3.61-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langsmith<0.4,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.3.42-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Downloading pydantic-2.11.5-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading sqlalchemy-2.0.41-cp313-cp313-macosx_11_0_arm64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from langchain) (6.0.2)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<1.0.0,>=0.3.58->langchain)\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.58->langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting packaging<25,>=23.2 (from langchain-core<1.0.0,>=0.3.58->langchain)\n",
      "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (4.13.2)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.18-cp313-cp313-macosx_15_0_arm64.whl.metadata (41 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading zstandard-0.23.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (3.0 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading pydantic_core-2.33.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from requests<3,>=2->langchain) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from requests<3,>=2->langchain) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from requests<3,>=2->langchain) (2025.4.26)\n",
      "Collecting anyio (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain)\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Downloading langchain-0.3.25-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.3.61-py3-none-any.whl (438 kB)\n",
      "Downloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Downloading langsmith-0.3.42-py3-none-any.whl (360 kB)\n",
      "Downloading pydantic-2.11.5-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp313-cp313-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sqlalchemy-2.0.41-cp313-cp313-macosx_11_0_arm64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading orjson-3.10.18-cp313-cp313-macosx_15_0_arm64.whl (133 kB)\n",
      "Downloading packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Downloading zstandard-0.23.0-cp313-cp313-macosx_11_0_arm64.whl (633 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m633.4/633.4 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: zstandard, typing-inspection, tenacity, SQLAlchemy, sniffio, pydantic-core, packaging, orjson, jsonpointer, h11, annotated-types, requests-toolbelt, pydantic, jsonpatch, httpcore, anyio, httpx, langsmith, langchain-core, langchain-text-splitters, langchain\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 25.0\n",
      "    Uninstalling packaging-25.0:\n",
      "      Successfully uninstalled packaging-25.0\n",
      "Successfully installed SQLAlchemy-2.0.41 annotated-types-0.7.0 anyio-4.9.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.25 langchain-core-0.3.61 langchain-text-splitters-0.3.8 langsmith-0.3.42 orjson-3.10.18 packaging-24.2 pydantic-2.11.5 pydantic-core-2.33.2 requests-toolbelt-1.0.0 sniffio-1.3.1 tenacity-9.1.2 typing-inspection-0.4.1 zstandard-0.23.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.24-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.59 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from langchain-community) (0.3.61)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.25 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from langchain-community) (0.3.25)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from langchain-community) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from langchain-community) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from langchain-community) (6.0.2)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain-community)\n",
      "  Downloading aiohttp-3.12.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from langchain-community) (9.1.2)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from langchain-community) (0.3.42)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: numpy>=2.1.0 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from langchain-community) (2.2.6)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading frozenlist-1.6.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (16 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading multidict-6.4.4-cp313-cp313-macosx_11_0_arm64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading propcache-0.3.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (10 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading yarl-1.20.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (72 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from langchain<1.0.0,>=0.3.25->langchain-community) (0.3.8)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from langchain<1.0.0,>=0.3.25->langchain-community) (2.11.5)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (4.13.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
      "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from requests<3,>=2->langchain-community) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from requests<3,>=2->langchain-community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from requests<3,>=2->langchain-community) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from requests<3,>=2->langchain-community) (2025.4.26)\n",
      "Requirement already satisfied: anyio in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.59->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community) (2.33.2)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
      "Downloading langchain_community-0.3.24-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.12.0-cp313-cp313-macosx_11_0_arm64.whl (452 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading frozenlist-1.6.0-cp313-cp313-macosx_11_0_arm64.whl (120 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading multidict-6.4.4-cp313-cp313-macosx_11_0_arm64.whl (37 kB)\n",
      "Downloading propcache-0.3.1-cp313-cp313-macosx_11_0_arm64.whl (44 kB)\n",
      "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading yarl-1.20.0-cp313-cp313-macosx_11_0_arm64.whl (94 kB)\n",
      "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Installing collected packages: python-dotenv, propcache, mypy-extensions, multidict, marshmallow, httpx-sse, frozenlist, attrs, aiohappyeyeballs, yarl, typing-inspect, aiosignal, pydantic-settings, dataclasses-json, aiohttp, langchain-community\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.0 aiosignal-1.3.2 attrs-25.3.0 dataclasses-json-0.6.7 frozenlist-1.6.0 httpx-sse-0.4.0 langchain-community-0.3.24 marshmallow-3.26.1 multidict-6.4.4 mypy-extensions-1.1.0 propcache-0.3.1 pydantic-settings-2.9.1 python-dotenv-1.1.0 typing-inspect-0.9.0 yarl-1.20.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting chromadb\n",
      "  Downloading chromadb-1.0.10-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.9 kB)\n",
      "Collecting build>=1.0.3 (from chromadb)\n",
      "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: pydantic>=1.9 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from chromadb) (2.11.5)\n",
      "Collecting fastapi==0.115.9 (from chromadb)\n",
      "  Downloading fastapi-0.115.9-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: numpy>=1.22.5 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from chromadb) (2.2.6)\n",
      "Collecting posthog>=2.4.0 (from chromadb)\n",
      "  Downloading posthog-4.2.0-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from chromadb) (4.13.2)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Downloading onnxruntime-1.22.0-cp313-cp313-macosx_13_0_universal2.whl.metadata (4.5 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_api-1.33.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.33.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.54b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_sdk-1.33.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting tokenizers>=0.13.2 (from chromadb)\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.65.0 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from chromadb) (4.67.1)\n",
      "Collecting overrides>=7.3.1 (from chromadb)\n",
      "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting importlib-resources (from chromadb)\n",
      "  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting grpcio>=1.58.0 (from chromadb)\n",
      "  Downloading grpcio-1.71.0-cp313-cp313-macosx_10_14_universal2.whl.metadata (3.8 kB)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\n",
      "  Downloading bcrypt-4.3.0-cp39-abi3-macosx_10_12_universal2.whl.metadata (10 kB)\n",
      "Collecting typer>=0.9.0 (from chromadb)\n",
      "  Downloading typer-0.15.4-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\n",
      "  Downloading kubernetes-32.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from chromadb) (9.1.2)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from chromadb) (6.0.2)\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\n",
      "  Downloading mmh3-5.1.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (16 kB)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from chromadb) (3.10.18)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from chromadb) (0.28.1)\n",
      "Collecting rich>=10.11.0 (from chromadb)\n",
      "  Downloading rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting jsonschema>=4.19.0 (from chromadb)\n",
      "  Downloading jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting starlette<0.46.0,>=0.40.0 (from fastapi==0.115.9->chromadb)\n",
      "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging>=19.1 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from build>=1.0.3->chromadb) (24.2)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
      "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: anyio in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from httpx>=0.27.0->chromadb) (4.9.0)\n",
      "Requirement already satisfied: certifi in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from httpx>=0.27.0->chromadb) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=4.19.0->chromadb)\n",
      "  Downloading jsonschema_specifications-2025.4.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=4.19.0->chromadb)\n",
      "  Downloading referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=4.19.0->chromadb)\n",
      "  Downloading rpds_py-0.25.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading google_auth-2.40.2-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: requests in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from kubernetes>=28.1.0->chromadb) (2.4.0)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading protobuf-6.31.0-cp39-abi3-macosx_10_9_universal2.whl.metadata (593 bytes)\n",
      "Collecting sympy (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting importlib-metadata<8.7.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Downloading importlib_metadata-8.6.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.33.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.33.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-proto==1.33.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_proto-1.33.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading protobuf-5.29.4-cp38-abi3-macosx_10_9_universal2.whl.metadata (592 bytes)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.54b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.54b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation==0.54b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_instrumentation-0.54b1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.54b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_semantic_conventions-0.54b1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-util-http==0.54b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_util_http-0.54b1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting wrapt<2.0.0,>=1.0.0 (from opentelemetry-instrumentation==0.54b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading wrapt-1.17.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.54b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting distro>=1.5.0 (from posthog>=2.4.0->chromadb)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from pydantic>=1.9->chromadb) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from pydantic>=1.9->chromadb) (0.4.1)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->chromadb)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from rich>=10.11.0->chromadb) (2.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from tokenizers>=0.13.2->chromadb) (0.32.0)\n",
      "Collecting click<8.2,>=8.0.0 (from typer>=0.9.0->chromadb)\n",
      "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading httptools-0.6.4-cp313-cp313-macosx_11_0_arm64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.0)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading uvloop-0.21.0-cp313-cp313-macosx_10_13_universal2.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading watchfiles-1.0.5-cp313-cp313-macosx_11_0_arm64.whl.metadata (4.9 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading websockets-15.0.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: filelock in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.5.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.1.2)\n",
      "Collecting zipp>=3.20 (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb)\n",
      "  Downloading zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.6.1 (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Downloading chromadb-1.0.10-cp39-abi3-macosx_11_0_arm64.whl (17.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading fastapi-0.115.9-py3-none-any.whl (94 kB)\n",
      "Downloading bcrypt-4.3.0-cp39-abi3-macosx_10_12_universal2.whl (498 kB)\n",
      "Downloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
      "Downloading grpcio-1.71.0-cp313-cp313-macosx_10_14_universal2.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "Downloading kubernetes-32.0.1-py2.py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mmh3-5.1.0-cp313-cp313-macosx_11_0_arm64.whl (40 kB)\n",
      "Downloading onnxruntime-1.22.0-cp313-cp313-macosx_13_0_universal2.whl (34.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.3/34.3 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_api-1.33.1-py3-none-any.whl (65 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_grpc-1.33.1-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.33.1-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.33.1-py3-none-any.whl (55 kB)\n",
      "Downloading opentelemetry_instrumentation_fastapi-0.54b1-py3-none-any.whl (12 kB)\n",
      "Downloading opentelemetry_instrumentation-0.54b1-py3-none-any.whl (31 kB)\n",
      "Downloading opentelemetry_instrumentation_asgi-0.54b1-py3-none-any.whl (16 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.54b1-py3-none-any.whl (194 kB)\n",
      "Downloading opentelemetry_util_http-0.54b1-py3-none-any.whl (7.3 kB)\n",
      "Downloading opentelemetry_sdk-1.33.1-py3-none-any.whl (118 kB)\n",
      "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Downloading posthog-4.2.0-py2.py3-none-any.whl (96 kB)\n",
      "Downloading rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "Downloading tokenizers-0.21.1-cp39-abi3-macosx_11_0_arm64.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typer-0.15.4-py3-none-any.whl (45 kB)\n",
      "Downloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
      "Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
      "Downloading google_auth-2.40.2-py2.py3-none-any.whl (216 kB)\n",
      "Downloading googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Downloading httptools-0.6.4-cp313-cp313-macosx_11_0_arm64.whl (102 kB)\n",
      "Downloading importlib_metadata-8.6.1-py3-none-any.whl (26 kB)\n",
      "Downloading jsonschema_specifications-2025.4.1-py3-none-any.whl (18 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Downloading protobuf-5.29.4-cp38-abi3-macosx_10_9_universal2.whl (417 kB)\n",
      "Downloading referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Downloading rpds_py-0.25.1-cp313-cp313-macosx_11_0_arm64.whl (350 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
      "Downloading uvloop-0.21.0-cp313-cp313-macosx_10_13_universal2.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading watchfiles-1.0.5-cp313-cp313-macosx_11_0_arm64.whl (392 kB)\n",
      "Downloading websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "Downloading websockets-15.0.1-cp313-cp313-macosx_11_0_arm64.whl (173 kB)\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Downloading wrapt-1.17.2-cp313-cp313-macosx_11_0_arm64.whl (38 kB)\n",
      "Downloading zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Building wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53801 sha256=2be990e90f49e9e897ed6903d97da9fdf4dbf31626ded634d4c667a378dda09d\n",
      "  Stored in directory: /Users/rudraprakashpandey/Library/Caches/pip/wheels/b4/f8/a5/28e9c1524d320f4b8eefdce0e487b5c2e128dbf2ed1bb4a60b\n",
      "Successfully built pypika\n",
      "Installing collected packages: pypika, mpmath, flatbuffers, durationpy, zipp, wrapt, websockets, websocket-client, uvloop, sympy, shellingham, rpds-py, pyproject_hooks, pyasn1, protobuf, overrides, opentelemetry-util-http, oauthlib, mmh3, mdurl, importlib-resources, humanfriendly, httptools, grpcio, distro, click, cachetools, bcrypt, backoff, asgiref, watchfiles, uvicorn, starlette, rsa, requests-oauthlib, referencing, pyasn1-modules, posthog, opentelemetry-proto, markdown-it-py, importlib-metadata, googleapis-common-protos, deprecated, coloredlogs, build, tokenizers, rich, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, onnxruntime, jsonschema-specifications, google-auth, fastapi, typer, opentelemetry-semantic-conventions, kubernetes, jsonschema, opentelemetry-sdk, opentelemetry-instrumentation, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb\n",
      "Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.3.0 build-1.2.2.post1 cachetools-5.5.2 chromadb-1.0.10 click-8.1.8 coloredlogs-15.0.1 deprecated-1.2.18 distro-1.9.0 durationpy-0.10 fastapi-0.115.9 flatbuffers-25.2.10 google-auth-2.40.2 googleapis-common-protos-1.70.0 grpcio-1.71.0 httptools-0.6.4 humanfriendly-10.0 importlib-metadata-8.6.1 importlib-resources-6.5.2 jsonschema-4.23.0 jsonschema-specifications-2025.4.1 kubernetes-32.0.1 markdown-it-py-3.0.0 mdurl-0.1.2 mmh3-5.1.0 mpmath-1.3.0 oauthlib-3.2.2 onnxruntime-1.22.0 opentelemetry-api-1.33.1 opentelemetry-exporter-otlp-proto-common-1.33.1 opentelemetry-exporter-otlp-proto-grpc-1.33.1 opentelemetry-instrumentation-0.54b1 opentelemetry-instrumentation-asgi-0.54b1 opentelemetry-instrumentation-fastapi-0.54b1 opentelemetry-proto-1.33.1 opentelemetry-sdk-1.33.1 opentelemetry-semantic-conventions-0.54b1 opentelemetry-util-http-0.54b1 overrides-7.7.0 posthog-4.2.0 protobuf-5.29.4 pyasn1-0.6.1 pyasn1-modules-0.4.2 pypika-0.48.9 pyproject_hooks-1.2.0 referencing-0.36.2 requests-oauthlib-2.0.0 rich-14.0.0 rpds-py-0.25.1 rsa-4.9.1 shellingham-1.5.4 starlette-0.45.3 sympy-1.14.0 tokenizers-0.21.1 typer-0.15.4 uvicorn-0.34.2 uvloop-0.21.0 watchfiles-1.0.5 websocket-client-1.8.0 websockets-15.0.1 wrapt-1.17.2 zipp-3.21.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-4.1.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Downloading transformers-4.52.3-py3-none-any.whl.metadata (40 kB)\n",
      "Requirement already satisfied: tqdm in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from sentence-transformers) (4.67.1)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Downloading torch-2.7.0-cp313-none-macosx_11_0_arm64.whl.metadata (29 kB)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Downloading scikit_learn-1.6.1-cp313-cp313-macosx_12_0_arm64.whl.metadata (31 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Downloading scipy-1.15.3-cp313-cp313-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from sentence-transformers) (0.32.0)\n",
      "Collecting Pillow (from sentence-transformers)\n",
      "  Downloading pillow-11.2.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from sentence-transformers) (4.13.2)\n",
      "Requirement already satisfied: filelock in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.5.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.2)\n",
      "Collecting setuptools (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached setuptools-80.8.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Collecting networkx (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.2.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->sentence-transformers)\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rudraprakashpandey/Documents/code/Vscode/venv/lib/python3.13/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.4.26)\n",
      "Downloading sentence_transformers-4.1.0-py3-none-any.whl (345 kB)\n",
      "Downloading torch-2.7.0-cp313-none-macosx_11_0_arm64.whl (68.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.6/68.6 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.52.3-py3-none-any.whl (10.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pillow-11.2.1-cp313-cp313-macosx_11_0_arm64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.6.1-cp313-cp313-macosx_12_0_arm64.whl (11.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.15.3-cp313-cp313-macosx_14_0_arm64.whl (22.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.4/22.4 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Downloading safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl (418 kB)\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached setuptools-80.8.0-py3-none-any.whl (1.2 MB)\n",
      "Installing collected packages: threadpoolctl, setuptools, scipy, safetensors, Pillow, networkx, joblib, torch, scikit-learn, transformers, sentence-transformers\n",
      "Successfully installed Pillow-11.2.1 joblib-1.5.1 networkx-3.4.2 safetensors-0.5.3 scikit-learn-1.6.1 scipy-1.15.3 sentence-transformers-4.1.0 setuptools-80.8.0 threadpoolctl-3.6.0 torch-2.7.0 transformers-4.52.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# For installing the libraries & downloading models from HF Hub\n",
    "%pip install huggingface_hub\n",
    "%pip install tiktoken\n",
    "%pip install pymupdf\n",
    "%pip install langchain\n",
    "%pip install langchain-community\n",
    "%pip install chromadb\n",
    "%pip install sentence-transformers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 832,
     "status": "ok",
     "timestamp": 1747497064337,
     "user": {
      "displayName": "Vidhya Subramanian",
      "userId": "14385231092771658629"
     },
     "user_tz": 300
    },
    "id": "RTY9GN4oWK3g"
   },
   "outputs": [],
   "source": [
    "#Libraries for downloading and loading the llm\n",
    "from huggingface_hub import hf_hub_download\n",
    "from llama_cpp import Llama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TtZWqj0wFTS1"
   },
   "source": [
    "## Question Answering using LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uq1lhM4WFTS2"
   },
   "source": [
    "#### Downloading and Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2776,
     "status": "ok",
     "timestamp": 1747497119341,
     "user": {
      "displayName": "Vidhya Subramanian",
      "userId": "14385231092771658629"
     },
     "user_tz": 300
    },
    "id": "dA3XQMWmQLJp",
    "outputId": "8d4e80e5-4fa7-474f-a334-ee93eb3923ec"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_load_from_file_impl: using device Metal (Apple M4) - 9434 MiB free\n",
      "llama_model_loader: loaded meta data with 24 key-value pairs and 291 tensors from /Users/rudraprakashpandey/.cache/huggingface/hub/models--TheBloke--Mistral-7B-Instruct-v0.2-GGUF/snapshots/3a6fbf4a41a1d52e415a4958cde6856d34b2db93/mistral-7b-instruct-v0.2.Q6_K.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = mistralai_mistral-7b-instruct-v0.2\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 1000000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 18\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:            tokenizer.ggml.padding_token_id u32              = 0\n",
      "llama_model_loader: - kv  20:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  21:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  22:                    tokenizer.chat_template str              = {{ bos_token }}{% for message in mess...\n",
      "llama_model_loader: - kv  23:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q6_K:  226 tensors\n",
      "print_info: file format = GGUF V3 (latest)\n",
      "print_info: file type   = Q6_K\n",
      "print_info: file size   = 5.53 GiB (6.56 BPW) \n",
      "init_tokenizer: initializing tokenizer for type 1\n",
      "load: control token:      2 '</s>' is not marked as EOG\n",
      "load: control token:      1 '<s>' is not marked as EOG\n",
      "load: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n",
      "load: special tokens cache size = 3\n",
      "load: token to piece cache size = 0.1637 MB\n",
      "print_info: arch             = llama\n",
      "print_info: vocab_only       = 0\n",
      "print_info: n_ctx_train      = 32768\n",
      "print_info: n_embd           = 4096\n",
      "print_info: n_layer          = 32\n",
      "print_info: n_head           = 32\n",
      "print_info: n_head_kv        = 8\n",
      "print_info: n_rot            = 128\n",
      "print_info: n_swa            = 0\n",
      "print_info: n_swa_pattern    = 1\n",
      "print_info: n_embd_head_k    = 128\n",
      "print_info: n_embd_head_v    = 128\n",
      "print_info: n_gqa            = 4\n",
      "print_info: n_embd_k_gqa     = 1024\n",
      "print_info: n_embd_v_gqa     = 1024\n",
      "print_info: f_norm_eps       = 0.0e+00\n",
      "print_info: f_norm_rms_eps   = 1.0e-05\n",
      "print_info: f_clamp_kqv      = 0.0e+00\n",
      "print_info: f_max_alibi_bias = 0.0e+00\n",
      "print_info: f_logit_scale    = 0.0e+00\n",
      "print_info: f_attn_scale     = 0.0e+00\n",
      "print_info: n_ff             = 14336\n",
      "print_info: n_expert         = 0\n",
      "print_info: n_expert_used    = 0\n",
      "print_info: causal attn      = 1\n",
      "print_info: pooling type     = 0\n",
      "print_info: rope type        = 0\n",
      "print_info: rope scaling     = linear\n",
      "print_info: freq_base_train  = 1000000.0\n",
      "print_info: freq_scale_train = 1\n",
      "print_info: n_ctx_orig_yarn  = 32768\n",
      "print_info: rope_finetuned   = unknown\n",
      "print_info: ssm_d_conv       = 0\n",
      "print_info: ssm_d_inner      = 0\n",
      "print_info: ssm_d_state      = 0\n",
      "print_info: ssm_dt_rank      = 0\n",
      "print_info: ssm_dt_b_c_rms   = 0\n",
      "print_info: model type       = 7B\n",
      "print_info: model params     = 7.24 B\n",
      "print_info: general.name     = mistralai_mistral-7b-instruct-v0.2\n",
      "print_info: vocab type       = SPM\n",
      "print_info: n_vocab          = 32000\n",
      "print_info: n_merges         = 0\n",
      "print_info: BOS token        = 1 '<s>'\n",
      "print_info: EOS token        = 2 '</s>'\n",
      "print_info: UNK token        = 0 '<unk>'\n",
      "print_info: PAD token        = 0 '<unk>'\n",
      "print_info: LF token         = 13 '<0x0A>'\n",
      "print_info: EOG token        = 2 '</s>'\n",
      "print_info: max token length = 48\n",
      "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
      "load_tensors: layer   0 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   1 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   2 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   3 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   4 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   5 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   6 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   7 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   8 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   9 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  10 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  11 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  12 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  13 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  14 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  15 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  16 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  17 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  18 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  19 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  20 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  21 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  22 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  23 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  24 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  25 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  26 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  27 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  28 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  29 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  30 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  31 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  32 assigned to device CPU, is_swa = 0\n",
      "load_tensors: tensor 'token_embd.weight' (q6_K) (and 218 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model downloaded to: /Users/rudraprakashpandey/.cache/huggingface/hub/models--TheBloke--Mistral-7B-Instruct-v0.2-GGUF/snapshots/3a6fbf4a41a1d52e415a4958cde6856d34b2db93/mistral-7b-instruct-v0.2.Q6_K.gguf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ggml_backend_metal_log_allocated_size: allocated buffer, size =  1365.27 MiB, ( 2853.62 / 10922.67)\n",
      "load_tensors: offloading 8 repeating layers to GPU\n",
      "load_tensors: offloaded 8/33 layers to GPU\n",
      "load_tensors: Metal_Mapped model buffer size =  1365.26 MiB\n",
      "load_tensors:   CPU_Mapped model buffer size =  5666.09 MiB\n",
      "...................................................................................................\n",
      "llama_context: constructing llama_context\n",
      "llama_context: n_seq_max     = 1\n",
      "llama_context: n_ctx         = 2300\n",
      "llama_context: n_ctx_per_seq = 2300\n",
      "llama_context: n_batch       = 128\n",
      "llama_context: n_ubatch      = 128\n",
      "llama_context: causal_attn   = 1\n",
      "llama_context: flash_attn    = 0\n",
      "llama_context: freq_base     = 1000000.0\n",
      "llama_context: freq_scale    = 1\n",
      "llama_context: n_ctx_per_seq (2300) < n_ctx_train (32768) -- the full capacity of the model will not be utilized\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: found device: Apple M4\n",
      "ggml_metal_init: picking default device: Apple M4\n",
      "ggml_metal_init: GPU name:   Apple M4\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyApple9  (1009)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyCommon3 (3003)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyMetal3  (5001)\n",
      "ggml_metal_init: simdgroup reduction   = true\n",
      "ggml_metal_init: simdgroup matrix mul. = true\n",
      "ggml_metal_init: has residency sets    = true\n",
      "ggml_metal_init: has bfloat            = true\n",
      "ggml_metal_init: use bfloat            = false\n",
      "ggml_metal_init: hasUnifiedMemory      = true\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize  = 11453.25 MB\n",
      "ggml_metal_init: loaded kernel_add                                    0x16fa2c7c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_row                                0x13acfa270 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sub                                    0x16d8ee160 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sub_row                                0x16de9ac70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul                                    0x16de9b040 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_row                                0x16de9b410 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_div                                    0x16de9b7e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_div_row                                0x107b50160 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_f32                             0x16d8ee560 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_f16                             0x16d8ee910 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_i32                             0x16d8eece0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_i16                             0x16fa29f00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_scale                                  0x16de9bbb0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_scale_4                                0x16de9bf80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_clamp                                  0x107b51b00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_tanh                                   0x10ae697d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_relu                                   0x107b504f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sigmoid                                0x16de9c350 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu                                   0x16de9c720 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_4                                 0x16de86760 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_quick                             0x17e5f56d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_quick_4                           0x16d8ef0b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_silu                                   0x16de86a90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_silu_4                                 0x107b507b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_elu                                    0x17e5f5ad0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f16                           0x16d8ef640 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f16_4                         0x16d8ef900 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f32                           0x107b50a70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f32_4                         0x107b50d30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_diag_mask_inf                          0x107b50ff0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_diag_mask_inf_8                        0x17e5f5ea0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_f32                           0x17e5f6240 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_f16                           0x10ae71960 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_get_rows_bf16                     (not supported)\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_0                          0x16de86e90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_1                          0x17e5f6610 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_0                          0x13acf6950 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_1                          0x16de87260 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q8_0                          0x16d8efc30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q2_K                          0x13acf6c10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q3_K                          0x16de87630 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_K                          0x16d8f0280 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_K                          0x16de87a00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q6_K                          0x13acf6ed0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq2_xxs                       0x17e5f6a10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq2_xs                        0x13acf7190 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq3_xxs                       0x16de87dd0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq3_s                         0x16de881a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq2_s                         0x16d8f0750 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq1_s                         0x13acfd7f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq1_m                         0x16de88570 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq4_nl                        0x16de88940 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq4_xs                        0x17e5f6de0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_i32                           0x13acfdab0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rms_norm                               0x17e5f71b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_l2_norm                                0x17e5f7550 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_group_norm                             0x17e5f7920 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_norm                                   0x17e5f7cf0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_ssm_conv_f32                           0x13acfdd70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_ssm_scan_f32                           0x16de88d10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rwkv_wkv6_f32                          0x16de890e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rwkv_wkv7_f32                          0x13acf7970 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f32_f32                         0x16d8f0af0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_1row              (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_l4                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_bf16                  (not supported)\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f32                         0x17e5f80c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f32_1row                    0x16d8f0f00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f32_l4                      0x16de894b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f16                         0x17e5f84c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q4_0_f32                        0x17e5f8860 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q4_1_f32                        0x17e5f8c30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q5_0_f32                        0x16d8f1230 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q5_1_f32                        0x16de89880 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q8_0_f32                        0x16d8f1560 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_f16_f32_r1_2                0x16d8f1820 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_f16_f32_r1_3                0x16de89c50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_f16_f32_r1_4                0x16de8a020 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_f16_f32_r1_5                0x16de8a3f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_0_f32_r1_2               0x13acf7c30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_0_f32_r1_3               0x13acf7ef0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_0_f32_r1_4               0x16de8a7c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_0_f32_r1_5               0x13acf8290 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_1_f32_r1_2               0x16de8ab90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_1_f32_r1_3               0x16d8f1ae0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_1_f32_r1_4               0x16de8af60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_1_f32_r1_5               0x13acf8660 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_0_f32_r1_2               0x13acf8a30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_0_f32_r1_3               0x17e5f9000 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_0_f32_r1_4               0x16de8b330 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_0_f32_r1_5               0x16de8b700 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_1_f32_r1_2               0x16de8bad0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_1_f32_r1_3               0x16de8bea0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_1_f32_r1_4               0x17e5f9400 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_1_f32_r1_5               0x16de8c270 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q8_0_f32_r1_2               0x16de8c640 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q8_0_f32_r1_3               0x16de8ca10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q8_0_f32_r1_4               0x13acf8e00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q8_0_f32_r1_5               0x17e5f97d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_K_f32_r1_2               0x16de8cde0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_K_f32_r1_3               0x16de8d1b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_K_f32_r1_4               0x16de8d580 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_K_f32_r1_5               0x16d8f2160 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_K_f32_r1_2               0x16de8d950 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_K_f32_r1_3               0x16de8dd20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_K_f32_r1_4               0x16de8e0f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_K_f32_r1_5               0x16d8f2420 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q6_K_f32_r1_2               0x16d8f26e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q6_K_f32_r1_3               0x17e5f9ba0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q6_K_f32_r1_4               0x16de8e4c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q6_K_f32_r1_5               0x17e5f9f40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_iq4_nl_f32_r1_2             0x17e5fa310 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_iq4_nl_f32_r1_3             0x16d8f2c70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_iq4_nl_f32_r1_4             0x16de8e890 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_iq4_nl_f32_r1_5             0x17e5fa710 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q2_K_f32                        0x16d8f2f30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q3_K_f32                        0x16d8f31f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q4_K_f32                        0x16de8ec60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q5_K_f32                        0x17e5faae0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q6_K_f32                        0x17e5fae80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq2_xxs_f32                     0x13acf92a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq2_xs_f32                      0x16de8f030 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq3_xxs_f32                     0x13acf9600 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq3_s_f32                       0x13acfaa80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq2_s_f32                       0x16de8f400 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq1_s_f32                       0x16de8f7d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq1_m_f32                       0x16de8fba0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq4_nl_f32                      0x13acfadd0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq4_xs_f32                      0x16de8ff70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_f32_f32                      0x17e5fb250 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_f16_f32                      0x16d8f3590 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_bf16_f32                (not supported)\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q4_0_f32                     0x17e5fb620 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q4_1_f32                     0x13acf34a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q5_0_f32                     0x17e5fbc50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q5_1_f32                     0x17e5fbf10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q8_0_f32                     0x17e5fc1d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q2_K_f32                     0x16de90340 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q3_K_f32                     0x16de90710 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q4_K_f32                     0x17e5fc570 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q5_K_f32                     0x17e5fc940 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q6_K_f32                     0x16d8f39f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq2_xxs_f32                  0x16de6f6b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq2_xs_f32                   0x16de6f970 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq3_xxs_f32                  0x10ae6de50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq3_s_f32                    0x17e5fcd10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq2_s_f32                    0x13acf3760 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq1_s_f32                    0x16de6fca0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq1_m_f32                    0x16d8f3e40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq4_nl_f32                   0x17e5fd1b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq4_xs_f32                   0x13acf3a90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_f32_f32                         0x13acf3df0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_f16_f32                         0x13acf41c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mm_bf16_f32                   (not supported)\n",
      "ggml_metal_init: loaded kernel_mul_mm_q4_0_f32                        0x16de70070 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q4_1_f32                        0x16de70440 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q5_0_f32                        0x16de70810 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q5_1_f32                        0x16de70be0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q8_0_f32                        0x16de70fb0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q2_K_f32                        0x13acf4590 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q3_K_f32                        0x17e5fd610 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q4_K_f32                        0x13acf4960 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q5_K_f32                        0x13acf4d30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q6_K_f32                        0x16de71380 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq2_xxs_f32                     0x17e5fd8d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq2_xs_f32                      0x17e5fdc50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq3_xxs_f32                     0x13acf5100 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq3_s_f32                       0x16d8f4350 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq2_s_f32                       0x16de71750 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq1_s_f32                       0x13acf54d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq1_m_f32                       0x16de71b20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq4_nl_f32                      0x13acf58a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq4_xs_f32                      0x13acf5c70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_f32_f32                      0x16de71ef0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_f16_f32                      0x13acf6040 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_bf16_f32                (not supported)\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q4_0_f32                     0x13acf2480 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q4_1_f32                     0x16de722c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q5_0_f32                     0x17e5fe020 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q5_1_f32                     0x17e5fe3f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q8_0_f32                     0x16de72690 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q2_K_f32                     0x13acf2850 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q3_K_f32                     0x13acf2c20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q4_K_f32                     0x16de72a60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q5_K_f32                     0x13acf2ff0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q6_K_f32                     0x16de72e30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq2_xxs_f32                  0x16d8f4820 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq2_xs_f32                   0x16d8f4ae0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq3_xxs_f32                  0x16d8f4e40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq3_s_f32                    0x16de73200 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq2_s_f32                    0x16de735d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq1_s_f32                    0x16de739a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq1_m_f32                    0x17e5fe7c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq4_nl_f32                   0x16de73d70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq4_xs_f32                   0x16d8f52e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_norm_f32                          0x16de74140 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_norm_f16                          0x16de74510 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_neox_f32                          0x16d8f55a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_neox_f16                          0x16de748e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_f16                             0x16de74cb0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_f32                             0x16de75080 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_ext_f16                         0x17e5feb90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_ext_f32                         0x16d8f5ac0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_conv_transpose_1d_f32_f32              0x16de75450 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_conv_transpose_1d_f16_f32              0x16de75820 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_upscale_f32                            0x16de75bf0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pad_f32                                0x16d8f5f60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pad_reflect_1d_f32                     0x16d8f6220 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_timestep_embedding_f32                 0x16d8f6580 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_arange_f32                             0x17e5fef60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_argsort_f32_i32_asc                    0x10273d170 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_argsort_f32_i32_desc                   0x16de75fc0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_leaky_relu_f32                         0x13acf0520 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h64                 0x17e5ff330 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h80                 0x17e5ff700 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h96                 0x17e5ffaa0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h112                0x16de76390 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h128                0x13acf08f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h192                0x13acf0cc0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_hk192_hv128         0x13acf1090 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h256                0x16de76760 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_hk576_hv512         0x17ffff020 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h192          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_hk192_hv128   (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_hk576_hv512   (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h64                0x16d8f6840 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h80                0x16d8f6c10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h96                0x16d8f6ff0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h112               0x13acf1530 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h128               0x13acf1890 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h192               0x16de76b30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_hk192_hv128        0x13acedc70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h256               0x17ffff2e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_hk576_hv512        0x16d8f7600 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h64                0x16d8f78c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h80                0x16d8f7c20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h96                0x13acedf30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h112               0x17ffff610 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h128               0x16de76f00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h192               0x13acee1f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_hk192_hv128        0x13aceaae0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h256               0x13aceada0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_hk576_hv512        0x16de772d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h64                0x16de776a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h80                0x17ffff9e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h96                0x16de77a70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h112               0x13aceb0d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h128               0x13aceb4a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h192               0x16de77e40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_hk192_hv128        0x16de78210 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h256               0x16d8f81a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_hk576_hv512        0x13aceb870 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h64                0x17ffe75b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h80                0x16de78670 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h96                0x16de789d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h112               0x16de78d70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h128               0x16de79140 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h192               0x16de79510 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_hk192_hv128        0x13acebc40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h256               0x16de798e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_hk576_hv512        0x17ffe7870 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h64                0x17ffe7b30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h80                0x17ffe7ed0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h96                0x16de79e20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h112               0x16de7a0e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h128               0x16de7a460 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h192               0x16de7a830 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_hk192_hv128        0x17ffe82a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h256               0x16de7ac00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_hk576_hv512        0x17ffe8670 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_h96             0x17ffe8a40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h96       (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_h96            0x13acec010 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_h96            0x10ae70b60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_h96            0x16de7afd0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_h96            0x13acec3e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_h96            0x13acec7b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_h128            0x16de7b3a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h128      (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_h128           0x13acecb80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_h128           0x17ffe8e10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_h128           0x13acecf50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_h128           0x10ae71240 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_h128           0x13aced320 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_h192            0x13aced6f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h192      (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_h192           0x13ace8ba0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_h192           0x13ace8f70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_h192           0x16d8f8670 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_h192           0x13ace9340 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_h192           0x13ace9710 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_hk192_hv128      0x17ffe91e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_hk192_hv128 (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_hk192_hv128      0x16de7b770 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_hk192_hv128      0x13ace9ae0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_hk192_hv128      0x16de7bb40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_hk192_hv128      0x16de7bf10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_hk192_hv128      0x17ffe95b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_h256            0x17ffe9980 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h256      (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_h256           0x16d8f8ac0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_h256           0x16de7c2e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_h256           0x13ace9f80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_h256           0x16de7c6b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_h256           0x16de7ca80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_hk576_hv512      0x16de7ce50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_hk576_hv512 (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_hk576_hv512      0x17ffe9d50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_hk576_hv512      0x13acea2e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_hk576_hv512      0x17ffea120 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_hk576_hv512      0x16de7d2b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_hk576_hv512      0x17ffea4f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_f32                                0x13ace80c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_i32                                0x16de7d610 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_f32                            0x16de7d9b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_f16                            0x16de7dd80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_cpy_f32_bf16                      (not supported)\n",
      "ggml_metal_init: loaded kernel_cpy_f16_f32                            0x16de7e150 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f16_f16                            0x17ffea8c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_f32                      (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_bf16                     (not supported)\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q8_0                           0x16d8f8d80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q4_0                           0x16de7e520 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q4_1                           0x16de7e8f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q5_0                           0x13ace83c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q5_1                           0x16de7ecc0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_iq4_nl                         0x16de7f090 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q4_0_f32                           0x16de7f460 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q4_0_f16                           0x16d8f9120 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q4_1_f32                           0x16de7f830 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q4_1_f16                           0x17ffeac90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q5_0_f32                           0x16de7fc00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q5_0_f16                           0x13ace6a80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q5_1_f32                           0x13ace6d40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q5_1_f16                           0x13ace7090 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q8_0_f32                           0x13ace7460 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q8_0_f16                           0x16d8f93e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_concat                                 0x13ace3b30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sqr                                    0x17ffeb060 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sqrt                                   0x17ffeb430 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sin                                    0x17ffeb800 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cos                                    0x13ace3f00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_neg                                    0x17ffebbd0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sum_rows                               0x17ffebfa0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_argmax                                 0x17ffec370 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pool_2d_avg_f32                        0x16d8f96a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pool_2d_max_f32                        0x17ffec740 | th_max = 1024 | th_width =   32\n",
      "set_abort_callback: call\n",
      "llama_context:        CPU  output buffer size =     0.12 MiB\n",
      "create_memory: n_ctx = 2304 (padded)\n",
      "llama_kv_cache_unified: kv_size = 2304, type_k = 'f16', type_v = 'f16', n_layer = 32, can_shift = 1, padding = 32\n",
      "llama_kv_cache_unified: layer   0: dev = CPU\n",
      "llama_kv_cache_unified: layer   1: dev = CPU\n",
      "llama_kv_cache_unified: layer   2: dev = CPU\n",
      "llama_kv_cache_unified: layer   3: dev = CPU\n",
      "llama_kv_cache_unified: layer   4: dev = CPU\n",
      "llama_kv_cache_unified: layer   5: dev = CPU\n",
      "llama_kv_cache_unified: layer   6: dev = CPU\n",
      "llama_kv_cache_unified: layer   7: dev = CPU\n",
      "llama_kv_cache_unified: layer   8: dev = CPU\n",
      "llama_kv_cache_unified: layer   9: dev = CPU\n",
      "llama_kv_cache_unified: layer  10: dev = CPU\n",
      "llama_kv_cache_unified: layer  11: dev = CPU\n",
      "llama_kv_cache_unified: layer  12: dev = CPU\n",
      "llama_kv_cache_unified: layer  13: dev = CPU\n",
      "llama_kv_cache_unified: layer  14: dev = CPU\n",
      "llama_kv_cache_unified: layer  15: dev = CPU\n",
      "llama_kv_cache_unified: layer  16: dev = CPU\n",
      "llama_kv_cache_unified: layer  17: dev = CPU\n",
      "llama_kv_cache_unified: layer  18: dev = CPU\n",
      "llama_kv_cache_unified: layer  19: dev = CPU\n",
      "llama_kv_cache_unified: layer  20: dev = CPU\n",
      "llama_kv_cache_unified: layer  21: dev = CPU\n",
      "llama_kv_cache_unified: layer  22: dev = CPU\n",
      "llama_kv_cache_unified: layer  23: dev = CPU\n",
      "llama_kv_cache_unified: layer  24: dev = Metal\n",
      "llama_kv_cache_unified: layer  25: dev = Metal\n",
      "llama_kv_cache_unified: layer  26: dev = Metal\n",
      "llama_kv_cache_unified: layer  27: dev = Metal\n",
      "llama_kv_cache_unified: layer  28: dev = Metal\n",
      "llama_kv_cache_unified: layer  29: dev = Metal\n",
      "llama_kv_cache_unified: layer  30: dev = Metal\n",
      "llama_kv_cache_unified: layer  31: dev = Metal\n",
      "llama_kv_cache_unified:      Metal KV buffer size =    72.00 MiB\n",
      "llama_kv_cache_unified:        CPU KV buffer size =   216.00 MiB\n",
      "llama_kv_cache_unified: KV self size  =  288.00 MiB, K (f16):  144.00 MiB, V (f16):  144.00 MiB\n",
      "llama_context: enumerating backends\n",
      "llama_context: backend_ptrs.size() = 3\n",
      "llama_context: max_nodes = 65536\n",
      "llama_context: worst-case: n_tokens = 128, n_seqs = 1, n_outputs = 0\n",
      "llama_context: reserving graph for n_tokens = 128, n_seqs = 1\n",
      "llama_context: reserving graph for n_tokens = 1, n_seqs = 1\n",
      "llama_context: reserving graph for n_tokens = 128, n_seqs = 1\n",
      "llama_context:      Metal compute buffer size =    45.13 MiB\n",
      "llama_context:        CPU compute buffer size =    45.13 MiB\n",
      "llama_context: graph nodes  = 1094\n",
      "llama_context: graph splits = 387 (with bs=128), 3 (with bs=1)\n",
      "Metal : EMBED_LIBRARY = 1 | CPU : ARM_FMA = 1 | FP16_VA = 1 | MATMUL_INT8 = 1 | DOTPROD = 1 | SME = 1 | ACCELERATE = 1 | AARCH64_REPACK = 1 | \n",
      "Model metadata: {'general.quantization_version': '2', 'tokenizer.chat_template': \"{{ bos_token }}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if message['role'] == 'user' %}{{ '[INST] ' + message['content'] + ' [/INST]' }}{% elif message['role'] == 'assistant' %}{{ message['content'] + eos_token}}{% else %}{{ raise_exception('Only user and assistant roles are supported!') }}{% endif %}{% endfor %}\", 'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.ggml.add_bos_token': 'true', 'tokenizer.ggml.padding_token_id': '0', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.model': 'llama', 'llama.attention.head_count_kv': '8', 'llama.context_length': '32768', 'llama.attention.head_count': '32', 'llama.rope.freq_base': '1000000.000000', 'llama.rope.dimension_count': '128', 'general.file_type': '18', 'llama.feed_forward_length': '14336', 'llama.embedding_length': '4096', 'llama.block_count': '32', 'general.architecture': 'llama', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'general.name': 'mistralai_mistral-7b-instruct-v0.2'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Guessed chat format: mistral-instruct\n"
     ]
    }
   ],
   "source": [
    "model_name_or_path = \"TheBloke/Mistral-7B-Instruct-v0.2-GGUF\"\n",
    "model_basename = \"mistral-7b-instruct-v0.2.Q6_K.gguf\"\n",
    "\n",
    "\n",
    "model_path = hf_hub_download(\n",
    "    repo_id=model_name_or_path,\n",
    "    filename=model_basename\n",
    ")\n",
    "\n",
    "print(f\"Model downloaded to: {model_path}\")\n",
    "\n",
    "llm = Llama(\n",
    "    model_path=model_path,\n",
    "    n_ctx=2300,\n",
    "    n_gpu_layers=8,\n",
    "    n_batch=128\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EzzkvIXvFTS4"
   },
   "source": [
    "#### Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1747497124145,
     "user": {
      "displayName": "Vidhya Subramanian",
      "userId": "14385231092771658629"
     },
     "user_tz": 300
    },
    "id": "hG_IaZj0QLw4"
   },
   "outputs": [],
   "source": [
    "# Temparature is kept at 0 because for this business use case we want factual answers\n",
    "\n",
    "def response(query,max_tokens=200,temperature=0,top_p=0.95,top_k=50):\n",
    "    model_output = llm(\n",
    "      prompt=query,\n",
    "      max_tokens=max_tokens,\n",
    "      temperature=temperature,\n",
    "      top_p=top_p,\n",
    "      top_k=top_k\n",
    "    )\n",
    "\n",
    "    return model_output['choices'][0]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K8YgK91SFjVY"
   },
   "source": [
    "### Query 1: What is the protocol for managing sepsis in a critical care unit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7445,
     "status": "ok",
     "timestamp": 1747497134337,
     "user": {
      "displayName": "Vidhya Subramanian",
      "userId": "14385231092771658629"
     },
     "user_tz": 300
    },
    "id": "-JLIVmpPQH0f",
    "outputId": "2c3cd876-711f-4507-b6c8-41342c3da0c9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =     711.25 ms /    16 tokens (   44.45 ms per token,    22.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =   15773.26 ms /   199 runs   (   79.26 ms per token,    12.62 tokens per second)\n",
      "llama_perf_context_print:       total time =   16510.03 ms /   215 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Sepsis is a life-threatening condition that can arise from an infection, and it requires prompt recognition and aggressive management in a critical care unit. The following are the general steps for managing sepsis in a critical care unit:\n",
      "\n",
      "1. Early recognition and suspicion: Septic patients may present with non-specific symptoms such as fever, chills, tachycardia, tachypnea, altered mental status, and lactic acidosis. It is essential to have a high index of suspicion for sepsis, especially in patients with known infections or risk factors.\n",
      "2. Initial assessment and resuscitation: The first step in managing sepsis is to assess and resuscitate the patient. This includes assessing airway, breathing, circulation, and disability (ABCD) and providing appropriate interventions such as oxygen therapy, fluid resuscitation, and vasopressor support as needed.\n",
      "3. Source control:\n"
     ]
    }
   ],
   "source": [
    "query1 = \"What is the protocol for managing sepsis in a critical care unit?\"\n",
    "print(response(query1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J6yxICeVFjVc"
   },
   "source": [
    "### Query 2: What are the common symptoms for appendicitis, and can it be cured via medicine? If not, what surgical procedure should be followed to treat it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8067,
     "status": "ok",
     "timestamp": 1747497145085,
     "user": {
      "displayName": "Vidhya Subramanian",
      "userId": "14385231092771658629"
     },
     "user_tz": 300
    },
    "id": "BdiHRgEqQIP9",
    "outputId": "0a2d3043-e307-4556-feba-e62ffcf4aeaa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 2 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    3113.49 ms\n",
      "llama_perf_context_print: prompt eval time =    1522.40 ms /    32 tokens (   47.58 ms per token,    21.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =   17317.64 ms /   199 runs   (   87.02 ms per token,    11.49 tokens per second)\n",
      "llama_perf_context_print:       total time =   18868.19 ms /   231 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Appendicitis is a medical condition characterized by inflammation of the appendix, a small tube-shaped organ located in the lower right side of the abdomen. The symptoms of appendicitis can vary from person to person, but the following are the most common:\n",
      "\n",
      "1. Abdominal pain: The pain is typically located in the lower right side of the abdomen and may start as a mild discomfort that gradually worsens. The pain may be constant or come and go, and it may be accompanied by cramping or bloating.\n",
      "2. Loss of appetite: People with appendicitis may lose their appetite and feel nauseous or vomit.\n",
      "3. Fever: A fever of 100.4°F (38°C) or higher is common in appendicitis.\n",
      "4. Diarrhea or constipation: Some people with appendicitis may experience diarrhea\n"
     ]
    }
   ],
   "source": [
    "query2 = \"What are the common symptoms for appendicitis, and can it be cured via medicine? If not, what surgical procedure should be followed to treat it?\"\n",
    "print(response(query2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oflaoOGiFjVd"
   },
   "source": [
    "### Query 3: What are the effective treatments or solutions for addressing sudden patchy hair loss, commonly seen as localized bald spots on the scalp, and what could be the possible causes behind it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7626,
     "status": "ok",
     "timestamp": 1747497152713,
     "user": {
      "displayName": "Vidhya Subramanian",
      "userId": "14385231092771658629"
     },
     "user_tz": 300
    },
    "id": "N-mx9yboQIt-",
    "outputId": "290972ad-f49f-4274-f709-3d4e5ce9d8cf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 4 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    3113.49 ms\n",
      "llama_perf_context_print: prompt eval time =    1665.91 ms /    34 tokens (   49.00 ms per token,    20.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =   16450.18 ms /   199 runs   (   82.66 ms per token,    12.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   18142.05 ms /   233 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Sudden patchy hair loss, also known as alopecia areata, is a common autoimmune disorder that affects the hair follicles, leading to hair loss in small, round patches on the scalp, beard, or other areas of the body. The exact cause of alopecia areata is not known, but it is believed to be related to a combination of genetic and environmental factors that trigger an abnormal immune response.\n",
      "\n",
      "There are several treatments and solutions that have been shown to be effective in addressing sudden patchy hair loss:\n",
      "\n",
      "1. Corticosteroids: Corticosteroids are anti-inflammatory medications that can help reduce inflammation and suppress the immune system, allowing the hair follicles to regrow. They can be applied topically or taken orally, depending on the severity and extent of the hair loss.\n",
      "2. Immunotherapy: Immunotherapy involves the use of medications\n"
     ]
    }
   ],
   "source": [
    "query3 = \"What are the effective treatments or solutions for addressing sudden patchy hair loss, commonly seen as localized bald spots on the scalp, and what could be the possible causes behind it?\"\n",
    "print(response(query3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WUUqY4FbFjVe"
   },
   "source": [
    "### Query 4:  What treatments are recommended for a person who has sustained a physical injury to brain tissue, resulting in temporary or permanent impairment of brain function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7464,
     "status": "ok",
     "timestamp": 1747497160142,
     "user": {
      "displayName": "Vidhya Subramanian",
      "userId": "14385231092771658629"
     },
     "user_tz": 300
    },
    "id": "TEsVMaKaQJzh",
    "outputId": "2f857a2a-b79d-45d7-bd51-41ec08a03391"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 2 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    3113.49 ms\n",
      "llama_perf_context_print: prompt eval time =    1066.98 ms /    28 tokens (   38.11 ms per token,    26.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =   17199.60 ms /   199 runs   (   86.43 ms per token,    11.57 tokens per second)\n",
      "llama_perf_context_print:       total time =   18293.63 ms /   227 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "There is no one-size-fits-all answer to this question, as the specific treatment recommendations for a person with a brain injury depend on the severity and location of the injury, as well as the individual's age, overall health, and other factors. However, there are some common treatments and interventions that may be recommended for individuals with brain injuries.\n",
      "\n",
      "1. Acute care: In the immediate aftermath of a brain injury, the focus is on providing acute care to stabilize the person's condition and prevent further damage. This may include:\n",
      "\n",
      "- Emergency medical care: If the brain injury is severe, the person may require emergency medical care, such as surgery to remove a hematoma or decompress a skull fracture.\n",
      "- Medications: Depending on the specific symptoms of the brain injury, the person may be prescribed medications to manage symptoms such as pain, swelling, or seizures.\n",
      "- Re\n"
     ]
    }
   ],
   "source": [
    "query4 = \"What treatments are recommended for a person who has sustained a physical injury to brain tissue, resulting in temporary or permanent impairment of brain function?\"\n",
    "print(response(query4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5laPFTHrFjVf"
   },
   "source": [
    "### Query 5: What are the necessary precautions and treatment steps for a person who has fractured their leg during a hiking trip, and what should be considered for their care and recovery?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7618,
     "status": "ok",
     "timestamp": 1747497167757,
     "user": {
      "displayName": "Vidhya Subramanian",
      "userId": "14385231092771658629"
     },
     "user_tz": 300
    },
    "id": "VfrlmrP5QKJz",
    "outputId": "0199207d-8811-423a-d49d-c4cb0418f4b8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 2 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    3113.49 ms\n",
      "llama_perf_context_print: prompt eval time =    1548.40 ms /    35 tokens (   44.24 ms per token,    22.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =   18090.06 ms /   199 runs   (   90.90 ms per token,    11.00 tokens per second)\n",
      "llama_perf_context_print:       total time =   19672.86 ms /   234 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "First and foremost, if a person has fractured their leg during a hiking trip, it is essential to ensure their safety and prevent further injury. Here are some necessary precautions and treatment steps:\n",
      "\n",
      "1. Assess the situation: Check the extent of the injury and assess the person's condition. If the fracture is open or the person is in severe pain, immobilize the leg with a splint or a makeshift sling to prevent any movement.\n",
      "2. Call for help: If possible, call for emergency medical assistance. If there is no cell phone reception, try to signal for help using a mirror, whistle, or other means.\n",
      "3. Provide first aid: Apply a sterile dressing to the injury to prevent infection. If the fracture is open, apply a clean cloth to stop the bleeding.\n",
      "4. Immobilize the leg: Use a splint, a makeshift sling, or\n"
     ]
    }
   ],
   "source": [
    "query5 = \"What are the necessary precautions and treatment steps for a person who has fractured their leg during a hiking trip, and what should be considered for their care and recovery?\"\n",
    "print(response(query5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g5myZ5dOOefc"
   },
   "source": [
    "## Question Answering using LLM with Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1747497171751,
     "user": {
      "displayName": "Vidhya Subramanian",
      "userId": "14385231092771658629"
     },
     "user_tz": 300
    },
    "id": "V6zMUxFl1CuR",
    "outputId": "8b97c506-de5c-4afc-ca78-6a031a8600f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System Prompt:You are a helpful and knowledgeable medical assistant. Answer the following medical question accurately and concisely based on common medical knowledge. If you don't know the answer, please state that you don't have enough information.\n"
     ]
    }
   ],
   "source": [
    "# Add instructions to the prompt for better response generation\n",
    "# Given the sensitivity of medical diagnosis, I am adding a prompt to minimize hallucination\n",
    "system_prompt = \"You are a helpful and knowledgeable medical assistant. Answer the following medical question accurately and concisely based on common medical knowledge. If you don't know the answer, please state that you don't have enough information.\"\n",
    "print (\"System Prompt:\" + system_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Jg3r_LWOeff"
   },
   "source": [
    "### Query 1: What is the protocol for managing sepsis in a critical care unit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7674,
     "status": "ok",
     "timestamp": 1747497186221,
     "user": {
      "displayName": "Vidhya Subramanian",
      "userId": "14385231092771658629"
     },
     "user_tz": 300
    },
    "id": "YqM4VMw5ROhX",
    "outputId": "87336292-1cb8-4315-b933-512a642821b1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 1 prefix-match hit, remaining 61 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =    1571.70 ms /    61 tokens (   25.77 ms per token,    38.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =   15922.62 ms /   199 runs   (   80.01 ms per token,    12.50 tokens per second)\n",
      "llama_perf_context_print:       total time =   17520.87 ms /   260 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sepsis is a life-threatening condition caused by a severe infection. In a critical care unit, managing sepsis involves the following steps:\n",
      "1. Early recognition and diagnosis: Identify sepsis early based on clinical signs and laboratory results, such as fever, tachycardia, tachypnea, low blood pressure, and elevated white blood cell count.\n",
      "2. Immediate fluid resuscitation: Administer intravenous fluids to maintain adequate blood pressure and organ perfusion.\n",
      "3. Antibiotic therapy: Start broad-spectrum antibiotics as soon as possible based on the suspected infection site and microbiological culture results.\n",
      "4. Source control: Identify and address the source of infection, such as removing an infected catheter or draining an abscess.\n",
      "5. Vasopressor support: If the patient's blood pressure remains low despite fluid resuscitation, administer vas\n"
     ]
    }
   ],
   "source": [
    "query1 = system_prompt + \"\\n\" + \"What is the protocol for managing sepsis in a critical care unit?\"\n",
    "print(response(query1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iYpyw4HjOeff"
   },
   "source": [
    "### Query 2: What are the common symptoms for appendicitis, and can it be cured via medicine? If not, what surgical procedure should be followed to treat it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7893,
     "status": "ok",
     "timestamp": 1747497194089,
     "user": {
      "displayName": "Vidhya Subramanian",
      "userId": "14385231092771658629"
     },
     "user_tz": 300
    },
    "id": "GXl09pFfRPBr",
    "outputId": "2e1b0398-1f14-4f46-8e67-dff73885416b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 48 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    3113.49 ms\n",
      "llama_perf_context_print: prompt eval time =    1449.14 ms /    32 tokens (   45.29 ms per token,    22.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =   17215.40 ms /   199 runs   (   86.51 ms per token,    11.56 tokens per second)\n",
      "llama_perf_context_print:       total time =   18693.23 ms /   231 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Appendicitis is a common inflammatory condition of the appendix, a small tube-shaped organ located in the lower right abdomen. The symptoms of appendicitis can include:\n",
      "\n",
      "1. Sudden pain in the lower right abdomen, which may start as a mild ache and gradually develop into a sharp pain.\n",
      "2. Loss of appetite and feeling sick to your stomach (nausea).\n",
      "3. Fever, which may be low-grade at first but can rise as high as 101°F (38.3°C) or higher.\n",
      "4. Vomiting, which may help relieve abdominal pain.\n",
      "5. Constipation or diarrhea.\n",
      "6. Inability to pass gas or have a bowel movement.\n",
      "7. Pain in the lower right quadrant of the abdomen when the doctor presses on it during a physical exam.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query2 = system_prompt + \"\\n\" + \"What are the common symptoms for appendicitis, and can it be cured via medicine? If not, what surgical procedure should be followed to treat it?\"\n",
    "print(response(query2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dRp92JQZOeff"
   },
   "source": [
    "### Query 3: What are the effective treatments or solutions for addressing sudden patchy hair loss, commonly seen as localized bald spots on the scalp, and what could be the possible causes behind it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7795,
     "status": "ok",
     "timestamp": 1747497201883,
     "user": {
      "displayName": "Vidhya Subramanian",
      "userId": "14385231092771658629"
     },
     "user_tz": 300
    },
    "id": "JOgATEpMRPve",
    "outputId": "6bf5345c-5489-4b01-a16a-48f6546ee0a7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 50 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    3113.49 ms\n",
      "llama_perf_context_print: prompt eval time =    1687.04 ms /    34 tokens (   49.62 ms per token,    20.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =   16727.44 ms /   199 runs   (   84.06 ms per token,    11.90 tokens per second)\n",
      "llama_perf_context_print:       total time =   18440.97 ms /   233 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Sudden patchy hair loss, also known as alopecia areata, is an autoimmune condition that causes hair loss in small, round patches on the scalp, beard, or other areas of the body. The exact cause is unknown, but it's believed to be related to a problem with the immune system.\n",
      "\n",
      "Effective treatments for addressing sudden patchy hair loss include:\n",
      "\n",
      "1. Corticosteroids: These are anti-inflammatory medications that can help reduce inflammation and suppress the immune system response. They can be applied topically or taken orally.\n",
      "2. Immunotherapy: This involves the use of medications that stimulate the immune system to attack the hair loss. One such medication is minoxidil.\n",
      "3. Hair transplantation: This is a surgical procedure in which healthy hair is transplanted from one area of the scalp to another. It's usually considered a\n"
     ]
    }
   ],
   "source": [
    "query3 = system_prompt + \"\\n\" + \"What are the effective treatments or solutions for addressing sudden patchy hair loss, commonly seen as localized bald spots on the scalp, and what could be the possible causes behind it?\"\n",
    "print(response(query3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AA45zwyUOefg"
   },
   "source": [
    "### Query 4:  What treatments are recommended for a person who has sustained a physical injury to brain tissue, resulting in temporary or permanent impairment of brain function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7685,
     "status": "ok",
     "timestamp": 1747497209565,
     "user": {
      "displayName": "Vidhya Subramanian",
      "userId": "14385231092771658629"
     },
     "user_tz": 300
    },
    "id": "VA7G8FOnRQZY",
    "outputId": "a5c7c16c-30a0-46d3-c279-432b761afa4e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 48 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    3113.49 ms\n",
      "llama_perf_context_print: prompt eval time =    1078.00 ms /    28 tokens (   38.50 ms per token,    25.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =   17183.78 ms /   199 runs   (   86.35 ms per token,    11.58 tokens per second)\n",
      "llama_perf_context_print:       total time =   18287.81 ms /   227 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "For a person who has sustained a physical injury to brain tissue, resulting in temporary or permanent impairment of brain function, the following treatments may be recommended based on common medical knowledge:\n",
      "\n",
      "1. Emergency care: If the injury is recent, the person may require emergency care to address any life-threatening conditions, such as airway obstruction, breathing difficulties, or excessive bleeding.\n",
      "2. Medications: Depending on the specific symptoms and conditions, various medications may be prescribed to manage symptoms, prevent complications, or improve brain function. For example, anti-inflammatory drugs may be used to reduce swelling, anticonvulsants to prevent seizures, or stimulants to improve attention and focus.\n",
      "3. Rehabilitation: Rehabilitation programs, including physical, occupational, and speech therapy, can help individuals regain lost skills and improve overall function. These therapies may focus on areas such as mobility,\n"
     ]
    }
   ],
   "source": [
    "query4 = system_prompt + \"\\n\" + \"What treatments are recommended for a person who has sustained a physical injury to brain tissue, resulting in temporary or permanent impairment of brain function?\"\n",
    "print(response(query4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TYXxiSuBOefg"
   },
   "source": [
    "### Query 5: What are the necessary precautions and treatment steps for a person who has fractured their leg during a hiking trip, and what should be considered for their care and recovery?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7660,
     "status": "ok",
     "timestamp": 1747497217223,
     "user": {
      "displayName": "Vidhya Subramanian",
      "userId": "14385231092771658629"
     },
     "user_tz": 300
    },
    "id": "mE2GMQk8RQ_p",
    "outputId": "8ec3f63d-5d6d-4740-95da-f6e43c7ce48a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 48 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    3113.49 ms\n",
      "llama_perf_context_print: prompt eval time =    1577.05 ms /    35 tokens (   45.06 ms per token,    22.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =   17460.75 ms /   199 runs   (   87.74 ms per token,    11.40 tokens per second)\n",
      "llama_perf_context_print:       total time =   19069.61 ms /   234 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "A leg fracture during a hiking trip requires prompt medical attention. Here are the necessary precautions and treatment steps:\n",
      "\n",
      "1. Immobilize the fracture: Use a splint or a sling to immobilize the affected leg to prevent further damage and pain. If the fracture is severe, do not move the person unless it is necessary to get them to medical help.\n",
      "2. Control bleeding: Apply direct pressure to the wound to control bleeding. If the bleeding does not stop, apply a sterile dressing and elevate the leg above heart level.\n",
      "3. Pain relief: Provide pain relief using over-the-counter pain medications such as acetaminophen or ibuprofen. If the pain is severe, the person may need prescription pain medication.\n",
      "4. Transport to medical help: Arrange for transportation to the nearest medical facility as soon as possible. If the person cannot be moved, call for emergency medical services.\n"
     ]
    }
   ],
   "source": [
    "query5 = system_prompt + \"\\n\" + \"What are the necessary precautions and treatment steps for a person who has fractured their leg during a hiking trip, and what should be considered for their care and recovery?\"\n",
    "print(response(query5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t_O1PGdNO2M9"
   },
   "source": [
    "## Data Preparation for RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uTpWESc53dL9"
   },
   "source": [
    "### Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 2085,
     "status": "ok",
     "timestamp": 1747497257776,
     "user": {
      "displayName": "Vidhya Subramanian",
      "userId": "14385231092771658629"
     },
     "user_tz": 300
    },
    "id": "ybj2cEnzRSXq"
   },
   "outputs": [],
   "source": [
    "## Data Preparation for RAG\n",
    "### Loading the Data\n",
    "#Libraries for processing dataframes, text\n",
    "import json, os\n",
    "import tiktoken\n",
    "import pandas as pd\n",
    "\n",
    "#Libraries for Loading Data, Chunking, Embedding, and Vector Databases\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ffj0ca3eZT4u"
   },
   "source": [
    "### Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 50191,
     "status": "ok",
     "timestamp": 1747497316145,
     "user": {
      "displayName": "Vidhya Subramanian",
      "userId": "14385231092771658629"
     },
     "user_tz": 300
    },
    "id": "PEw2UChp-i8f",
    "outputId": "d439b6c6-a18d-4439-f45b-0027d3076fa0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4114 pages from the PDF.\n"
     ]
    }
   ],
   "source": [
    "## Data Overview\n",
    "\n",
    "\n",
    "pdf_path = '/Users/rudraprakashpandey/Documents/code/Vscode/medical/medical_diagnosis_manual (1).pdf'\n",
    "if not os.path.exists(pdf_path):\n",
    "    raise FileNotFoundError(f\"PDF not found at {pdf_path}\")\n",
    "\n",
    "# Use the PyMuPDFLoader to load the document\n",
    "try:\n",
    "    # Note: Loading large PDFs (>4,000 pages) may require significant memory. Consider chunked processing if RAM is limited.\n",
    "    loader = PyMuPDFLoader(pdf_path)\n",
    "    documents = loader.load()\n",
    "    print(f\"Loaded {len(documents)} pages from the PDF.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading PDF: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f9weTDzMxRRS"
   },
   "source": [
    "#### Checking the first 5 pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1747497321832,
     "user": {
      "displayName": "Vidhya Subramanian",
      "userId": "14385231092771658629"
     },
     "user_tz": 300
    },
    "id": "MSEiL--bRTZT",
    "outputId": "e46b5fcc-75d2-41db-c7e4-109cae6b8ce8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Page 1 ---\n",
      "vistarathecompany@gmail.com\n",
      "6LVJBSDN4X\n",
      "for personal use by vistarathecompany@\n",
      "shing the contents in part or full is liable...\n",
      "--- Page 2 ---\n",
      "vistarathecompany@gmail.com\n",
      "6LVJBSDN4X\n",
      "This file is meant for personal use by vistarathecompany@gmail.com only.\n",
      "Sharing or publishing the contents in part or full is liable for legal action....\n",
      "--- Page 3 ---\n",
      "Table of Contents\n",
      "1\n",
      "Front    ................................................................................................................................................................................................................\n",
      "1\n",
      "Cover    .......................................................................................................................................................................................................\n",
      "2\n",
      "Front Matter    ....................................\n",
      "--- Page 4 ---\n",
      "491\n",
      "Chapter 44. Foot & Ankle Disorders    .....................................................................................................................................\n",
      "502\n",
      "Chapter 45. Tumors of Bones & Joints    ...............................................................................................................................\n",
      "510\n",
      "5 - Ear, Nose, Throat & Dental Disorders    ...........................................................................................................\n",
      "--- Page 5 ---\n",
      "921\n",
      "Chapter 94. Adrenal Disorders    ................................................................................................................................................\n",
      "936\n",
      "Chapter 95. Polyglandular Deficiency Syndromes    ........................................................................................................\n",
      "939\n",
      "Chapter 96. Porphyrias    ....................................................................................................................................\n",
      "Number of pages: 4114\n"
     ]
    }
   ],
   "source": [
    "# Preview first 5 pages (or fewer if PDF is smaller) for debugging\n",
    "for i in range(min(5, len(documents))):\n",
    "    print(f\"--- Page {i+1} ---\")\n",
    "    print(documents[i].page_content[:500] + \"...\")\n",
    "\n",
    "#### Checking the number of pages\n",
    "print(f\"Number of pages: {len(documents)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7-wNNalNxPKT"
   },
   "source": [
    "#### Checking the number of pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LECMxTH-zB-R"
   },
   "source": [
    "### Data Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1747497339628,
     "user": {
      "displayName": "Vidhya Subramanian",
      "userId": "14385231092771658629"
     },
     "user_tz": 300
    },
    "id": "ir9Zi8rKRUmG"
   },
   "outputs": [],
   "source": [
    "## Function to do data chunking\n",
    "\n",
    "def get_data_chunks(\n",
    "    data,\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    split_method=\"recursive\",\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    "    min_chunk_size=50,\n",
    "    respect_sentence_boundaries=True,\n",
    "    respect_paragraph_boundaries=True,\n",
    "    length_function=len,\n",
    "    max_chunks=None,\n",
    "    add_metadata=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Splits a list of documents into smaller chunks using a specified method.\n",
    "\n",
    "    Args:\n",
    "        data: A list of document objects (e.g., from Langchain loaders).\n",
    "        chunk_size: The maximum size of each chunk.\n",
    "        chunk_overlap: The number of characters to overlap between chunks.\n",
    "        split_method: The method to use for splitting ('recursive').\n",
    "        separators: A list of separators to use for splitting.\n",
    "        min_chunk_size: The minimum size of each chunk.\n",
    "        respect_sentence_boundaries: Whether to try to split on sentence boundaries.\n",
    "        respect_paragraph_boundaries: Whether to try to split on paragraph boundaries.\n",
    "        length_function: The function to use to measure chunk length.\n",
    "        max_chunks: The maximum number of chunks to generate.\n",
    "        add_metadata: Whether to add metadata to the chunks.\n",
    "\n",
    "    Returns:\n",
    "        A list of chunked documents.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if split_method == \"recursive\":\n",
    "            text_splitter = RecursiveCharacterTextSplitter(\n",
    "                chunk_size=chunk_size,\n",
    "                chunk_overlap=chunk_overlap,\n",
    "                length_function=length_function,\n",
    "                is_separator_regex=False,\n",
    "                separators=separators\n",
    "            )\n",
    "            chunks = text_splitter.split_documents(data)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported split_method: {split_method}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during chunking: {e}\")\n",
    "        raise\n",
    "    chunks = [chunk for chunk in chunks if length_function(chunk.page_content) >= min_chunk_size]\n",
    "    if add_metadata:\n",
    "        for chunk in chunks:\n",
    "            if not chunk.metadata:\n",
    "                chunk.metadata = {\"source\": \"medical_diagnosis_manual.pdf\", \"page\": 0}  # Fallback\n",
    "    if max_chunks is not None:\n",
    "        chunks = chunks[:max_chunks]\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 997,
     "status": "ok",
     "timestamp": 1747497364881,
     "user": {
      "displayName": "Vidhya Subramanian",
      "userId": "14385231092771658629"
     },
     "user_tz": 300
    },
    "id": "g9_lKsfRCGhv",
    "outputId": "2db50f56-5240-4da3-8e08-f296cfc07b9d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ggml_metal_free: deallocating\n",
      "ggml_metal_mem_pool_free: freeing memory pool, num heaps = 0 (total = 0)\n",
      "ggml_metal_mem_pool_free: freeing memory pool, num heaps = 0 (total = 0)\n",
      "ggml_metal_mem_pool_free: freeing memory pool, num heaps = 0 (total = 0)\n",
      "ggml_metal_mem_pool_free: freeing memory pool, num heaps = 0 (total = 0)\n",
      "ggml_metal_mem_pool_free: freeing memory pool, num heaps = 0 (total = 0)\n",
      "ggml_metal_mem_pool_free: freeing memory pool, num heaps = 0 (total = 0)\n",
      "ggml_metal_mem_pool_free: freeing memory pool, num heaps = 0 (total = 0)\n",
      "ggml_metal_mem_pool_free: freeing memory pool, num heaps = 0 (total = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Chunking Validation ---\n",
      "Number of documents loaded: 4114\n",
      "Number of chunks created: 34605\n",
      "\n",
      "First 5 chunks:\n",
      "--- Chunk 1 ---\n",
      "Chunk length: 122\n",
      "Chunk metadata: {'producer': 'pdf-lib (https://github.com/Hopding/pdf-lib)', 'creator': 'Atop CHM to PDF Converter', 'creationdate': '2012-06-15T05:44:40+00:00', 'source': '/Users/rudraprakashpandey/Documents/code/Vscode/medical/medical_diagnosis_manual (1).pdf', 'file_path': '/Users/rudraprakashpandey/Documents/code/Vscode/medical/medical_diagnosis_manual (1).pdf', 'total_pages': 4114, 'format': 'PDF 1.7', 'title': 'The Merck Manual of Diagnosis & Therapy, 19th Edition', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-13T02:35:28+00:00', 'trapped': '', 'modDate': 'D:20250513023528Z', 'creationDate': 'D:20120615054440Z', 'page': 0}\n",
      "vistarathecompany@gmail.com\n",
      "6LVJBSDN4X\n",
      "for personal use by vistarathecompany@\n",
      "shing the contents in part or full is liable...\n",
      "--- Chunk 2 ---\n",
      "Chunk length: 190\n",
      "Chunk metadata: {'producer': 'pdf-lib (https://github.com/Hopding/pdf-lib)', 'creator': 'Atop CHM to PDF Converter', 'creationdate': '2012-06-15T05:44:40+00:00', 'source': '/Users/rudraprakashpandey/Documents/code/Vscode/medical/medical_diagnosis_manual (1).pdf', 'file_path': '/Users/rudraprakashpandey/Documents/code/Vscode/medical/medical_diagnosis_manual (1).pdf', 'total_pages': 4114, 'format': 'PDF 1.7', 'title': 'The Merck Manual of Diagnosis & Therapy, 19th Edition', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-13T02:35:28+00:00', 'trapped': '', 'modDate': 'D:20250513023528Z', 'creationDate': 'D:20120615054440Z', 'page': 1}\n",
      "vistarathecompany@gmail.com\n",
      "6LVJBSDN4X\n",
      "This file is meant for personal use by vistarathecompany@gmail.com only.\n",
      "Sharing or publishing the contents in part or full is liable for legal action....\n",
      "--- Chunk 3 ---\n",
      "Chunk length: 450\n",
      "Chunk metadata: {'producer': 'pdf-lib (https://github.com/Hopding/pdf-lib)', 'creator': 'Atop CHM to PDF Converter', 'creationdate': '2012-06-15T05:44:40+00:00', 'source': '/Users/rudraprakashpandey/Documents/code/Vscode/medical/medical_diagnosis_manual (1).pdf', 'file_path': '/Users/rudraprakashpandey/Documents/code/Vscode/medical/medical_diagnosis_manual (1).pdf', 'total_pages': 4114, 'format': 'PDF 1.7', 'title': 'The Merck Manual of Diagnosis & Therapy, 19th Edition', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-13T02:35:28+00:00', 'trapped': '', 'modDate': 'D:20250513023528Z', 'creationDate': 'D:20120615054440Z', 'page': 2}\n",
      "Table of Contents\n",
      "1\n",
      "Front    ..............................................................................................................................................................................\n",
      "--- Chunk 4 ---\n",
      "Chunk length: 400\n",
      "Chunk metadata: {'producer': 'pdf-lib (https://github.com/Hopding/pdf-lib)', 'creator': 'Atop CHM to PDF Converter', 'creationdate': '2012-06-15T05:44:40+00:00', 'source': '/Users/rudraprakashpandey/Documents/code/Vscode/medical/medical_diagnosis_manual (1).pdf', 'file_path': '/Users/rudraprakashpandey/Documents/code/Vscode/medical/medical_diagnosis_manual (1).pdf', 'total_pages': 4114, 'format': 'PDF 1.7', 'title': 'The Merck Manual of Diagnosis & Therapy, 19th Edition', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-13T02:35:28+00:00', 'trapped': '', 'modDate': 'D:20250513023528Z', 'creationDate': 'D:20120615054440Z', 'page': 2}\n",
      "2\n",
      "Front Matter    .........................................................................................................................................................................................\n",
      "--- Chunk 5 ---\n",
      "Chunk length: 361\n",
      "Chunk metadata: {'producer': 'pdf-lib (https://github.com/Hopding/pdf-lib)', 'creator': 'Atop CHM to PDF Converter', 'creationdate': '2012-06-15T05:44:40+00:00', 'source': '/Users/rudraprakashpandey/Documents/code/Vscode/medical/medical_diagnosis_manual (1).pdf', 'file_path': '/Users/rudraprakashpandey/Documents/code/Vscode/medical/medical_diagnosis_manual (1).pdf', 'total_pages': 4114, 'format': 'PDF 1.7', 'title': 'The Merck Manual of Diagnosis & Therapy, 19th Edition', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-13T02:35:28+00:00', 'trapped': '', 'modDate': 'D:20250513023528Z', 'creationDate': 'D:20120615054440Z', 'page': 2}\n",
      "53\n",
      "Chapter 1. Nutrition: General Considerations    .....................................................................................................................\n",
      "59\n",
      "Chapter 2. Undernutrition   ...\n",
      "\n",
      "Last 5 chunks:\n",
      "--- Chunk 34601 ---\n",
      "Chunk length: 348\n",
      "Chunk metadata: {'producer': 'pdf-lib (https://github.com/Hopding/pdf-lib)', 'creator': 'Atop CHM to PDF Converter', 'creationdate': '2012-06-15T05:44:40+00:00', 'source': '/Users/rudraprakashpandey/Documents/code/Vscode/medical/medical_diagnosis_manual (1).pdf', 'file_path': '/Users/rudraprakashpandey/Documents/code/Vscode/medical/medical_diagnosis_manual (1).pdf', 'total_pages': 4114, 'format': 'PDF 1.7', 'title': 'The Merck Manual of Diagnosis & Therapy, 19th Edition', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-13T02:35:28+00:00', 'trapped': '', 'modDate': 'D:20250513023528Z', 'creationDate': 'D:20120615054440Z', 'page': 4112}\n",
      "Y. pestis infection 1924\n",
      "Yew poisoning 3338\n",
      "Yips 1762\n",
      "Yo, antibodies to 1056\n",
      "Yolk sac tumor 2476\n",
      "The Merck Manual of Diagnosis & Therapy, 19th Edition\n",
      "Y\n",
      "4103\n",
      "vistarathecompany@gmail.com\n",
      "6LVJBSDN4X\n",
      "Thi...\n",
      "--- Chunk 34602 ---\n",
      "Chunk length: 492\n",
      "Chunk metadata: {'producer': 'pdf-lib (https://github.com/Hopding/pdf-lib)', 'creator': 'Atop CHM to PDF Converter', 'creationdate': '2012-06-15T05:44:40+00:00', 'source': '/Users/rudraprakashpandey/Documents/code/Vscode/medical/medical_diagnosis_manual (1).pdf', 'file_path': '/Users/rudraprakashpandey/Documents/code/Vscode/medical/medical_diagnosis_manual (1).pdf', 'total_pages': 4114, 'format': 'PDF 1.7', 'title': 'The Merck Manual of Diagnosis & Therapy, 19th Edition', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-13T02:35:28+00:00', 'trapped': '', 'modDate': 'D:20250513023528Z', 'creationDate': 'D:20120615054440Z', 'page': 4113}\n",
      "Z\n",
      "Zafirlukast 1879\n",
      "Zalcitabine 1451\n",
      "in children 2854\n",
      "Zaleplon 1709\n",
      "Zanamivir 1407\n",
      "in influenza 1407, 1929\n",
      "ZAP-70 (zeta-associated protein 70) deficiency 1092, 1108\n",
      "Zavanelli maneuver 2680\n",
      "Zellweger sy...\n",
      "--- Chunk 34603 ---\n",
      "Chunk length: 484\n",
      "Chunk metadata: {'producer': 'pdf-lib (https://github.com/Hopding/pdf-lib)', 'creator': 'Atop CHM to PDF Converter', 'creationdate': '2012-06-15T05:44:40+00:00', 'source': '/Users/rudraprakashpandey/Documents/code/Vscode/medical/medical_diagnosis_manual (1).pdf', 'file_path': '/Users/rudraprakashpandey/Documents/code/Vscode/medical/medical_diagnosis_manual (1).pdf', 'total_pages': 4114, 'format': 'PDF 1.7', 'title': 'The Merck Manual of Diagnosis & Therapy, 19th Edition', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-13T02:35:28+00:00', 'trapped': '', 'modDate': 'D:20250513023528Z', 'creationDate': 'D:20120615054440Z', 'page': 4113}\n",
      "poisoning with 3328, 3353\n",
      "recommended dietary allowances for 50\n",
      "reference values for 3499\n",
      "toxicity of 49, 55\n",
      "copper deficiency and 49\n",
      "in Wilson's disease 52\n",
      "Zinc oxide 2233\n",
      "gelatin formulation of 646,...\n",
      "--- Chunk 34604 ---\n",
      "Chunk length: 459\n",
      "Chunk metadata: {'producer': 'pdf-lib (https://github.com/Hopding/pdf-lib)', 'creator': 'Atop CHM to PDF Converter', 'creationdate': '2012-06-15T05:44:40+00:00', 'source': '/Users/rudraprakashpandey/Documents/code/Vscode/medical/medical_diagnosis_manual (1).pdf', 'file_path': '/Users/rudraprakashpandey/Documents/code/Vscode/medical/medical_diagnosis_manual (1).pdf', 'total_pages': 4114, 'format': 'PDF 1.7', 'title': 'The Merck Manual of Diagnosis & Therapy, 19th Edition', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-13T02:35:28+00:00', 'trapped': '', 'modDate': 'D:20250513023528Z', 'creationDate': 'D:20120615054440Z', 'page': 4113}\n",
      "Zollinger-Ellison syndrome 95, 199, 200-201, 910\n",
      "mastocytosis vs 1125\n",
      "Menetrier's disease vs 132\n",
      "peptic ulcer disease vs 134\n",
      "Zolmitriptan 1721\n",
      "Zolpidem 1709, 3103\n",
      "Zonisamide 1701\n",
      "Zoonotic diseases, cu...\n",
      "--- Chunk 34605 ---\n",
      "Chunk length: 162\n",
      "Chunk metadata: {'producer': 'pdf-lib (https://github.com/Hopding/pdf-lib)', 'creator': 'Atop CHM to PDF Converter', 'creationdate': '2012-06-15T05:44:40+00:00', 'source': '/Users/rudraprakashpandey/Documents/code/Vscode/medical/medical_diagnosis_manual (1).pdf', 'file_path': '/Users/rudraprakashpandey/Documents/code/Vscode/medical/medical_diagnosis_manual (1).pdf', 'total_pages': 4114, 'format': 'PDF 1.7', 'title': 'The Merck Manual of Diagnosis & Therapy, 19th Edition', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-13T02:35:28+00:00', 'trapped': '', 'modDate': 'D:20250513023528Z', 'creationDate': 'D:20120615054440Z', 'page': 4113}\n",
      "6LVJBSDN4X\n",
      "This file is meant for personal use by vistarathecompany@gmail.com only.\n",
      "Sharing or publishing the contents in part or full is liable for legal action....\n",
      "\n",
      "Minimum chunk length: 122\n",
      "Number of empty chunks: 0\n",
      "Number of chunks missing metadata: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Utilize the get_data_chunks function for the loaded PDF\n",
    "chunk_size = 500  # chunk size\n",
    "chunk_overlap = 100 # chunk overlap\n",
    "\n",
    "chunks = get_data_chunks(\n",
    "    documents,\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    "    split_method=\"recursive\",\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    "    min_chunk_size=50,\n",
    "    respect_sentence_boundaries=True,\n",
    "    respect_paragraph_boundaries=True,\n",
    "    length_function=len,\n",
    "    max_chunks=None, # Process all chunks\n",
    "    add_metadata=True\n",
    ")\n",
    "\n",
    "# Print some validation and check statements\n",
    "print(f\"\\n--- Chunking Validation ---\")\n",
    "print(f\"Number of documents loaded: {len(documents)}\")\n",
    "print(f\"Number of chunks created: {len(chunks)}\")\n",
    "\n",
    "# Check the first few chunks\n",
    "print(f\"\\nFirst {min(5, len(chunks))} chunks:\")\n",
    "for i in range(min(5, len(chunks))):\n",
    "  print(f\"--- Chunk {i+1} ---\")\n",
    "  print(f\"Chunk length: {len(chunks[i].page_content)}\")\n",
    "  print(f\"Chunk metadata: {chunks[i].metadata}\")\n",
    "  print(chunks[i].page_content[:200] + \"...\") # Print first 200 characters of the chunk content\n",
    "\n",
    "# Check the last few chunks (if there are more than 5)\n",
    "if len(chunks) > 5:\n",
    "    print(f\"\\nLast {min(5, len(chunks)-5)} chunks:\")\n",
    "    for i in range(max(0, len(chunks)-5), len(chunks)):\n",
    "        print(f\"--- Chunk {i+1} ---\")\n",
    "        print(f\"Chunk length: {len(chunks[i].page_content)}\")\n",
    "        print(f\"Chunk metadata: {chunks[i].metadata}\")\n",
    "        print(chunks[i].page_content[:200] + \"...\") # Print first 200 characters of the chunk content\n",
    "\n",
    "# Additional checks\n",
    "if len(chunks) > 0:\n",
    "    # Check minimum chunk size\n",
    "    min_len = min(len(chunk.page_content) for chunk in chunks)\n",
    "    print(f\"\\nMinimum chunk length: {min_len}\")\n",
    "    if min_len < 50: # Based on min_chunk_size parameter\n",
    "        print(\"Warning: Some chunks might be smaller than the specified minimum size.\")\n",
    "\n",
    "    # Check for empty chunks\n",
    "    empty_chunks = sum(1 for chunk in chunks if len(chunk.page_content) == 0)\n",
    "    print(f\"Number of empty chunks: {empty_chunks}\")\n",
    "\n",
    "    # Check metadata presence (assuming add_metadata is True)\n",
    "    metadata_missing = sum(1 for chunk in chunks if not hasattr(chunk, 'metadata') or not chunk.metadata)\n",
    "    print(f\"Number of chunks missing metadata: {metadata_missing}\")\n",
    "else:\n",
    "    print(\"\\nNo chunks were created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BvHVejcWz0Bl"
   },
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 647,
     "referenced_widgets": [
      "0294b9bc5d2f44d09163237bcd68927d",
      "788a9ce6505f464bb05e798ada338ba4",
      "61a73dac3e2147888ca65a4ceb023ec5",
      "417783ced0c049acbf0d5a3fba5b2426",
      "f2ccf0fdb9934c9e990b75ae27a729da",
      "1101bbfbaf5c4abeba6f3746c54629dd",
      "27c2411bbaa545978b4363a294f87cd7",
      "2abd44767b5a41fdab727f5194423a55",
      "d7ef6d4469dc473f868d2bad3aab4828",
      "9190decfac64415eb455a427e4a0fbfe",
      "6b4f09ded6614a34ad8cb3a43c8bedaa",
      "874caf49704a49b7ad1bed017d579c6d",
      "e4481fe3f2f44a35934c9d6aced94941",
      "020d7d3934e04204aeb1bc66e64af1c7",
      "6a0fc1d3ebc444b8ba5a3de02e06b3d2",
      "57c511de322f4dd1a38885960ab3c9cf",
      "12396dda069842029d289643b9be6083",
      "1dc25300365d44a5a4edb1822f5fc487",
      "de4021eb3df64971abff623e2affa9cd",
      "812ca01252ee422693a1b5cf7852766c",
      "84dc01a7b87242a39c2e24383570e1ed",
      "5d399db616df4f15a6659a76fb4bf5b3",
      "4b712678d0254057b58ed3303bad94f7",
      "f66c5e89116a40f2aa04bed4adefb6d1",
      "543b93c3e984433d8bab0213b9a77f87",
      "7860d48fb9f44452a9e78537b853bd8e",
      "b6eb29a5b76e45b38a0ce826598cdd07",
      "e67638db8e2a467f92daead399145650",
      "50946886cf864c698d31f47513c0e9b6",
      "004dbb3b4dda406db8641b6df8b471dc",
      "4c4d0a3d6c9740edb9e9da5646ddc174",
      "294dcd8c75074479a6858054eab2d540",
      "3ae17e81478c470795ab369862d4c1f7",
      "73f3ee296b6349d2ac0d490a907822ad",
      "2b91f962e8ef4a089c0e55a4652d6efa",
      "05653f41b2d048db8c7a7311050e11f4",
      "a61c1bc8a7c541248394d1c83240e070",
      "01908b4c3692436bacc077e13b163da6",
      "246a978f6fe44570992457c8d3288992",
      "728613c663a4414ab0d37d66dfadbf56",
      "daf765af390c4057bae663e1346c0d0b",
      "73c85ac9767b4ce4bcee6561b0ef3009",
      "f3b966510aa7461dad137335cffe8c39",
      "984bea400e154cfb9acf6f88b4ae064c",
      "e46496cd547c4d07b20b3589a53a7ae7",
      "ee32c8a02f32487f90f46aa4f24cd88d",
      "c66b7e7e8e6a464e8d8e99023dcb4014",
      "439bf2f56ddf4923b00c7a9b068c44db",
      "cfb5f51567134988abc49f443ae22b42",
      "b24897dcb9454fdab7a376b41915530f",
      "01a50273972449dbbe1e9c9edf42a932",
      "b9bd8d1f8df14fdba410c0a43f1e48ba",
      "6882573750dc4b2bbb8dbd0b7f15649e",
      "63b36345134e4d67b1f7c32c7d248c46",
      "4d54d26b51e3441bbbd42604afcc174f",
      "a8c95e5e504146db9f57a1eab47cdbfb",
      "bf7c4b3ad8a449a7a66cd6873c197357",
      "dcf39f054da348469f662529b51a6c3f",
      "7e9388ed5baf45ae805655ab2f3eb7a3",
      "41a512e0cbbc4260a8903dfcfe5c7a74",
      "b1276ee2c3a449dcabc367beababb108",
      "79ed3c283a8d49618283c433f3896d56",
      "7d9b17e532ff40aba1bc293461e7deda",
      "4b98af2c3ab84907aeee173081a75163",
      "783b19f002d74710871eb992a6cba58a",
      "491063168b6c4e99b7c2d4a13f09431f",
      "1a8cc165211c40f1bd0224c73c0741a1",
      "366e54785395488ab011e88dd4431582",
      "dde78db6b7314ed5b8bc855bfc3ee83b",
      "441db1a0bab94ebc9a30f2959efcb19e",
      "757ab35fcd6b437cbf2cd6f02f003c39",
      "c967eebc0e9a4fb389298b2dbea5cc27",
      "fc22e13681bb41f58a7610e24ab0ecb0",
      "bb24a64ad998447390ebe96ec953b2a3",
      "bfcf8d7839bb4d0ebcfc635ac8220733",
      "0132362cb7dc405087e4a4b92e5dbb49",
      "60a53f485e254dad93537e40d1a2052e",
      "b5c670793eec4695af26fdb6275d1255",
      "671fe2339a454f7087ad5486708d27ef",
      "eac2627aaf5d4efa9700de758f0b7f78",
      "a3917dfe70f94e61b8ea2e6b09c07b6b",
      "5753f716481847d1bd5df05bbde1f46b",
      "c6d9415461894735968b730dc1049797",
      "5f04c98085cc452d8d2b261607ff245e",
      "8e0cbb347c8f4fd6a642b19318dfebfa",
      "a870c0b063a3464f9b9c9be43451ba55",
      "d96c01d2188240c697f78ef58a421e93",
      "b8c7104ed50343369e1db39279f630d3",
      "599b7be55846425abd3dc269df142ab0",
      "302a1d59b3e6486ea8192e89501167a7",
      "db05e703900c413ab323686dcf90d658",
      "1dff4b40189b45278f9c91f42a3f0a1b",
      "cb3500b9269c4cbfb7982af16946cca9",
      "53b82a55a85c46c3831585ab623639ec",
      "162744977d884c41a3f4714154846321",
      "0e58e7e78c754bbe91262e710857b53d",
      "2ccf33261e8244aaa78f35de441fe3a5",
      "1e7bf49c43dc41df8008ac5677ef1cea",
      "22264af3652d460884cdb736a66afe20",
      "f786eda4a6a14ebd9f58ed2ce1c8c986",
      "dc4b08518d19436d8d2238afc5d439ec",
      "6138dd2be99746a0a95677aeb2f378c8",
      "899930cfaee14f4da69bfe5d44eab72e",
      "8cd8f1285bb946da8dc29be6ce10cca0",
      "ceaee8123699400a8fccaedca33de802",
      "1e9043cd78b74228b3b17bfa00f6fd0a",
      "b0c7d04668aa468e8e14fcc34059f461",
      "256ac56e2bb84eddb5f64a2008bf1bd2",
      "f2cb49e40f6c4e8f85ecc983331188cf",
      "8d50f31db1c240abafd583b597e73543",
      "c756b5b005bf46adb9386746aeabde75",
      "7f9a8443a0a64b0285010e123eb3b41e",
      "2962d6b1aafd4d2cb8b6115d2686c761",
      "36590b88aaab41b3be490cb271fce656",
      "411fb81621fb404683ee1b0e8f90103b",
      "3fdddaf6266d4fd3baa601665a13355f",
      "8c78f0b438774217bc1ec91b117bfb58",
      "109692fe97f249f79a9316c788b97ff6",
      "4c9446a082824171a0d64116b6a2fb4d",
      "69b8ce2175dd410eb32938bd49571a97",
      "de273ed51a9940f3ad99ec8973d1942b",
      "fd36eedfcc524d0ab474c615a9c9b1d1",
      "0017b53b36ea4562aad1a3986d0605e2",
      "ac9082833f5548f9b63b2976930f58db",
      "132cb8ea082e405eaa869cda9cddbea6",
      "9994eed521c24fbe84f48663733df80b",
      "a9ab2158c9f548fb9a00742cc1aded21",
      "bb697fbb85ee492997c47e28714db00c",
      "25dfc1e7813c443b9e16750b91585366",
      "b4bf43b475f44f698136985ab12dd7a4",
      "843a56ab833d44fe837055d3481e19e0",
      "6492690370854073ba3e1ebdaf447202"
     ]
    },
    "executionInfo": {
     "elapsed": 164414,
     "status": "ok",
     "timestamp": 1747497598829,
     "user": {
      "displayName": "Vidhya Subramanian",
      "userId": "14385231092771658629"
     },
     "user_tz": 300
    },
    "id": "R3CAgoUeRVLa",
    "outputId": "7b8a24ba-b6db-48cf-b0b5-a9ed83dd6266"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2y/flkwlsc160n2tz5m70f_nt3m0000gn/T/ipykernel_1050/3405431599.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Embedding Validation ---\n",
      "Number of original chunks: 34605\n",
      "Number of successfully embedded chunks: 34605\n",
      "All chunks successfully embedded.\n",
      "Type of first embedding: <class 'list'>\n",
      "Dimension of first embedding: 384\n",
      "First 10 values: [-0.07890099  0.06623081  0.03226828 -0.04527882  0.03095172  0.01784509\n",
      "  0.03430261  0.01443451 -0.00089051 -0.02856948]\n"
     ]
    }
   ],
   "source": [
    "# Note: For M4 with 16GB RAM, process chunks in small batches to avoid memory issues.\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Embed chunks in batches\n",
    "embedded_chunks = []\n",
    "batch_size = 100  # Safe for 16GB RAM\n",
    "for i in range(0, len(chunks), batch_size):\n",
    "    batch = chunks[i:i+batch_size]\n",
    "    for j, chunk in enumerate(batch):\n",
    "        try:\n",
    "            embedding = embedding_function.embed_query(chunk.page_content)\n",
    "            embedded_chunks.append((chunk, embedding))\n",
    "        except Exception as e:\n",
    "            print(f\"Error embedding chunk {i+j}: {e}\")\n",
    "print(f\"\\n--- Embedding Validation ---\")\n",
    "print(f\"Number of original chunks: {len(chunks)}\")\n",
    "print(f\"Number of successfully embedded chunks: {len(embedded_chunks)}\")\n",
    "if len(embedded_chunks) == len(chunks):\n",
    "    print(\"All chunks successfully embedded.\")\n",
    "else:\n",
    "    print(f\"Embedded {len(embedded_chunks)}/{len(chunks)} chunks.\")\n",
    "\n",
    "if len(embedded_chunks) > 0:\n",
    "    first_embedded_chunk, first_embedding = embedded_chunks[0]\n",
    "    print(f\"Type of first embedding: {type(first_embedding)}\")\n",
    "    import numpy as np\n",
    "    first_embedding_np = np.array(first_embedding)\n",
    "    print(f\"Dimension of first embedding: {len(first_embedding_np)}\")\n",
    "    print(f\"First 10 values: {first_embedding_np[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qiKCOv4X0d7B"
   },
   "source": [
    "### Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 81103,
     "status": "ok",
     "timestamp": 1747497679941,
     "user": {
      "displayName": "Vidhya Subramanian",
      "userId": "14385231092771658629"
     },
     "user_tz": 300
    },
    "id": "vHHt1MQQRVzs",
    "outputId": "c52bdc23-aa14-41d6-8203-f4e7455bed6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created directory at medical_db\n",
      "\n",
      "--- Vector Database Validation ---\n",
      "Chroma database created at medical_db.\n",
      "Number of items in database: 34605\n",
      "Match with embedded chunks.\n"
     ]
    }
   ],
   "source": [
    "#Vector Database\n",
    "import os, shutil\n",
    "\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "persist_directory = 'medical_db'\n",
    "if os.path.exists(persist_directory):\n",
    "    print(f\"Removing existing database at {persist_directory}\")\n",
    "    shutil.rmtree(persist_directory, ignore_errors=True)\n",
    "\n",
    "if not os.path.exists(persist_directory):\n",
    "    os.makedirs(persist_directory)\n",
    "    print(f\"Created directory at {persist_directory}\")\n",
    "\n",
    "try:\n",
    "    vector_db = Chroma.from_documents(\n",
    "        documents=[chunk for chunk, embedding in embedded_chunks],\n",
    "        embedding=embedding_function,\n",
    "        persist_directory=persist_directory\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Error creating Chroma database: {e}\")\n",
    "    raise\n",
    "\n",
    "# Simplified vector database validation\n",
    "print(f\"\\n--- Vector Database Validation ---\")\n",
    "if os.path.exists(persist_directory):\n",
    "    print(f\"Chroma database created at {persist_directory}.\")\n",
    "try:\n",
    "    count = vector_db._collection.count()\n",
    "    print(f\"Number of items in database: {count}\")\n",
    "    print(\"Match with embedded chunks.\" if count == len(embedded_chunks) else \"Item count mismatch.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error retrieving database count: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uEa5sKc41T1z"
   },
   "source": [
    "### Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 90,
     "status": "ok",
     "timestamp": 1747497810604,
     "user": {
      "displayName": "Vidhya Subramanian",
      "userId": "14385231092771658629"
     },
     "user_tz": 300
    },
    "id": "wBlQUGx3RWUD",
    "outputId": "840c631d-3d4c-4e9d-8aca-ff12bd23e2ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Retriever Validation ---\n",
      "Conclusion: Retriever successfully created.\n",
      "\n",
      "Retrieved 3 documents for a sample query.\n",
      "Sample of retrieved document content (first 100 chars):\n",
      "Symptoms and Signs\n",
      "The classic symptoms of acute appendicitis are epigastric or periumbilical pain f...\n",
      "\n",
      "Retriever configuration:\n",
      "Search type: similarity\n",
      "Search kwargs: {'k': 3}\n",
      "Conclusion: Retriever configured with correct k value (3).\n"
     ]
    }
   ],
   "source": [
    "# prompt: code a retriever using the above code with the appropriate search method and k value\n",
    "retriever = vector_db.as_retriever(\n",
    "    search_type=\"similarity\",  # Using similarity search\n",
    "    search_kwargs={\"k\": 3}     # Retrieve top 3 similar documents\n",
    ")\n",
    "\n",
    "# --- Validation and Conclusions ---\n",
    "print(f\"\\n--- Retriever Validation ---\")\n",
    "if retriever:\n",
    "    print(\"Conclusion: Retriever successfully created.\")\n",
    "    try:\n",
    "        # Test with queries from problem statement (e.g., sepsis, appendicitis, hair loss)\n",
    "        sample_query = \"What are the symptoms of appendicitis?\"\n",
    "        retrieved_docs = retriever.invoke(sample_query)\n",
    "        print(f\"\\nRetrieved {len(retrieved_docs)} documents for a sample query.\")\n",
    "        if len(retrieved_docs) > 0:\n",
    "            print(\"Sample of retrieved document content (first 100 chars):\")\n",
    "            print(retrieved_docs[0].page_content[:100] + \"...\")\n",
    "        else:\n",
    "            print(\"No documents retrieved. Check vector database content or query relevance.\")\n",
    "        \n",
    "        print(f\"\\nRetriever configuration:\")\n",
    "        print(f\"Search type: {retriever.search_type}\")\n",
    "        print(f\"Search kwargs: {retriever.search_kwargs}\")\n",
    "        if retriever.search_kwargs.get(\"k\") == 3:\n",
    "            print(\"Conclusion: Retriever configured with correct k value (3).\")\n",
    "        else:\n",
    "            print(f\"Warning: Retriever's k value is {retriever.search_kwargs.get('k')}, expected 3.\")\n",
    "    except ValueError as ve:\n",
    "        print(f\"Database error during retrieval: {ve}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during sample query with retriever: {e}\")\n",
    "        print(\"Conclusion: Retriever might not be configured correctly or database has issues.\")\n",
    "else:\n",
    "    print(\"Conclusion: Failed to create the retriever.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vw8qcwq66B0C",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### System and User Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "SSJhTwkDOWg3"
   },
   "outputs": [],
   "source": [
    "## 1. The system message describing the assistant's role.\n",
    "## 2. A user message template including context and the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- System and User Prompts ---\n",
    "qna_system_message = \"You are a knowledgeable medical assistant. Provide accurate, concise answers based solely on the provided context from the Merck Manuals. If the context is insufficient, state that you lack information.\"\n",
    "qna_user_message_template = \"\"\"Context: {context}\\n\\nQuestion: {question}\\nAnswer concisely and factually.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Evaluation Prompts ---\n",
    "groundedness_rater_system_message = \"You are an evaluator assessing the groundedness of a medical response. Rate the response based on whether all factual claims are supported by the provided context, on a scale of 1–5 (1: contradicts context, 5: fully supported). Return only the numeric rating.\"\n",
    "relevance_rater_system_message = \"You are an evaluator assessing the relevance of a medical response. Rate the response based on how directly it addresses the question, on a scale of 1–5 (1: irrelevant, 5: fully relevant). Return only the numeric rating.\"\n",
    "user_message_template = \"\"\"Question: {question}\\nResponse: {answer}\\nContext: {context}\\nRating:\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Queries to Test ---\n",
    "queries_to_test = {\n",
    "    \"Query 1\": \"What is the protocol for managing sepsis in a critical care unit?\",\n",
    "    \"Query 2\": \"What are the common symptoms for appendicitis, and can it be cured via medicine? If not, what surgical procedure should be followed to treat it?\",\n",
    "    \"Query 3\": \"What are the effective treatments or solutions for addressing sudden patchy hair loss, commonly seen as localized bald spots on the scalp, and what could be the possible causes behind it?\",\n",
    "    \"Query 4\": \"What treatments are recommended for a person who has sustained a physical injury to brain tissue, resulting in temporary or permanent impairment of brain function?\",\n",
    "    \"Query 5\": \"What are the necessary precautions and treatment steps for a person who has fractured their leg during a hiking trip, and what should be considered for their care and recovery?\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- RAG Response Function ---\n",
    "def generate_rag_response(user_input, retriever, max_tokens=128, temperature=0, top_p=0.95, top_k=50):\n",
    "    global qna_system_message, qna_user_message_template\n",
    "    try:\n",
    "        relevant_document_chunks = retriever.invoke(user_input)\n",
    "        context_list = [d.page_content for d in relevant_document_chunks]\n",
    "        context_for_query = \". \".join(context_list)[:4000]  # Limit for M4\n",
    "        user_message = qna_user_message_template.replace('{context}', context_for_query).replace('{question}', user_input)\n",
    "        prompt = f\"{qna_system_message}\\n{user_message}\".strip()\n",
    "        response = llm(\n",
    "            prompt=prompt,\n",
    "            max_tokens=max_tokens,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            top_k=top_k\n",
    "        )\n",
    "        return response['choices'][0]['text'].strip(), context_for_query\n",
    "    except ValueError as ve:\n",
    "        return f\"Retrieval error: {ve}\", \"\"\n",
    "    except Exception as e:\n",
    "        return f\"Sorry, I encountered the following error: {e}\", \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Groundedness and Relevance Evaluation Function ---\n",
    "def generate_ground_relevance_response(user_input, retriever, max_tokens=10, temperature=0, top_p=0.95, top_k=50):\n",
    "    global groundedness_rater_system_message, relevance_rater_system_message, user_message_template\n",
    "    try:\n",
    "        # Generate RAG response and get context\n",
    "        answer, context_for_query = generate_rag_response(user_input, retriever, max_tokens=128, temperature=0)\n",
    "        \n",
    "        # Groundedness evaluation\n",
    "        groundedness_prompt = user_message_template.format(\n",
    "            question=user_input,\n",
    "            answer=answer,\n",
    "            context=context_for_query\n",
    "        )\n",
    "        groundedness_response = llm(\n",
    "            prompt=f\"{groundedness_rater_system_message}\\n{groundedness_prompt}\",\n",
    "            max_tokens=max_tokens,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            top_k=top_k\n",
    "        )\n",
    "        groundedness_rating = groundedness_response['choices'][0]['text'].strip()\n",
    "\n",
    "        # Relevance evaluation\n",
    "        relevance_prompt = user_message_template.format(\n",
    "            question=user_input,\n",
    "            answer=answer,\n",
    "            context=context_for_query\n",
    "        )\n",
    "        relevance_response = llm(\n",
    "            prompt=f\"{relevance_rater_system_message}\\n{relevance_prompt}\",\n",
    "            max_tokens=max_tokens,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            top_k=top_k\n",
    "        )\n",
    "        relevance_rating = relevance_response['choices'][0]['text'].strip()\n",
    "\n",
    "        return groundedness_rating, relevance_rating, answer, context_for_query\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\", f\"Error: {e}\", \"\", \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Fine-tuning Parameters ---\n",
    "param_combinations = [\n",
    "    {\"chunk_size\": 500, \"chunk_overlap\": 100, \"retriever_k\": 3, \"llm_max_tokens\": 128, \"llm_temperature\": 0},\n",
    "    {\"chunk_size\": 750, \"chunk_overlap\": 150, \"retriever_k\": 5, \"llm_max_tokens\": 200, \"llm_temperature\": 0.1},\n",
    "    {\"chunk_size\": 1000, \"chunk_overlap\": 200, \"retriever_k\": 3, \"llm_max_tokens\": 128, \"llm_temperature\": 0},\n",
    "    {\"chunk_size\": 500, \"chunk_overlap\": 100, \"retriever_k\": 5, \"llm_max_tokens\": 200, \"llm_temperature\": 0.2},\n",
    "    {\"chunk_size\": 750, \"chunk_overlap\": 150, \"retriever_k\": 3, \"llm_max_tokens\": 128, \"llm_temperature\": 0.1}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Fine-tuning RAG Parameters ---\n",
      "\n",
      "--- Combination 1: {'chunk_size': 500, 'chunk_overlap': 100, 'retriever_k': 3, 'llm_max_tokens': 128, 'llm_temperature': 0} ---\n",
      "  Created 34605 chunks.\n",
      "  Embedded 34605 chunks.\n",
      "  Retriever created with k=3\n",
      "    Testing Query: Query 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 4 prefix-match hit, remaining 400 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   11237.62 ms /   400 tokens (   28.09 ms per token,    35.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =   12917.36 ms /    99 runs   (  130.48 ms per token,     7.66 tokens per second)\n",
      "llama_perf_context_print:       total time =   24178.02 ms /   499 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 517 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   10851.99 ms /   517 tokens (   20.99 ms per token,    47.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1099.45 ms /     9 runs   (  122.16 ms per token,     8.19 tokens per second)\n",
      "llama_perf_context_print:       total time =   11956.04 ms /   526 tokens\n",
      "Llama.generate: 9 prefix-match hit, remaining 503 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   11238.87 ms /   503 tokens (   22.34 ms per token,    44.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =     944.30 ms /     9 runs   (  104.92 ms per token,     9.53 tokens per second)\n",
      "llama_perf_context_print:       total time =   12185.07 ms /   512 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Response: The protocol for managing sepsis in a critical care unit includes controlling hemorrhage, checking and providing respiratory assistance if necessary, keeping the patient warm, avoiding anything by mou...\n",
      "    Groundedness Rating: 5\n",
      "Explanation: The response is\n",
      "    Relevance Rating: 5\n",
      "Explanation: The response directly\n",
      "    Testing Query: Query 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 3 prefix-match hit, remaining 469 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   10842.61 ms /   469 tokens (   23.12 ms per token,    43.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =   15252.35 ms /   127 runs   (  120.10 ms per token,     8.33 tokens per second)\n",
      "llama_perf_context_print:       total time =   26127.09 ms /   596 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 614 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   12831.00 ms /   614 tokens (   20.90 ms per token,    47.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =     861.66 ms /     9 runs   (   95.74 ms per token,    10.45 tokens per second)\n",
      "llama_perf_context_print:       total time =   13694.16 ms /   623 tokens\n",
      "Llama.generate: 9 prefix-match hit, remaining 600 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   12843.93 ms /   600 tokens (   21.41 ms per token,    46.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =     159.54 ms /     2 runs   (   79.77 ms per token,    12.54 tokens per second)\n",
      "llama_perf_context_print:       total time =   13004.14 ms /   602 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Response: The common symptoms for appendicitis include epigastric or periumbilical pain followed by brief nausea, vomiting, and anorexia, which later shifts to the right lower quadrant. The pain increases with ...\n",
      "    Groundedness Rating: 5. The response accurately describes the common symptoms\n",
      "    Relevance Rating: 5\n",
      "    Testing Query: Query 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 3 prefix-match hit, remaining 453 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   10247.93 ms /   453 tokens (   22.62 ms per token,    44.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =   15925.43 ms /   127 runs   (  125.40 ms per token,     7.97 tokens per second)\n",
      "llama_perf_context_print:       total time =   26204.52 ms /   580 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 598 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   12572.16 ms /   598 tokens (   21.02 ms per token,    47.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =     883.94 ms /     9 runs   (   98.22 ms per token,    10.18 tokens per second)\n",
      "llama_perf_context_print:       total time =   13457.66 ms /   607 tokens\n",
      "Llama.generate: 9 prefix-match hit, remaining 584 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   13392.16 ms /   584 tokens (   22.93 ms per token,    43.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =     159.76 ms /     2 runs   (   79.88 ms per token,    12.52 tokens per second)\n",
      "llama_perf_context_print:       total time =   13552.57 ms /   586 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Response: Alopecia areata is a type of nonscarring alopecia characterized by sudden patchy hair loss. The scalp and beard are most commonly affected, but any hairy area may be involved. The cause is not clear, ...\n",
      "    Groundedness Rating: 5\n",
      "The response accurately identifies alo\n",
      "    Relevance Rating: 5\n",
      "    Testing Query: Query 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 3 prefix-match hit, remaining 423 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   10079.76 ms /   423 tokens (   23.83 ms per token,    41.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =   15766.32 ms /   127 runs   (  124.14 ms per token,     8.06 tokens per second)\n",
      "llama_perf_context_print:       total time =   25875.92 ms /   550 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 568 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   12784.19 ms /   568 tokens (   22.51 ms per token,    44.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1099.70 ms /     9 runs   (  122.19 ms per token,     8.18 tokens per second)\n",
      "llama_perf_context_print:       total time =   13885.79 ms /   577 tokens\n",
      "Llama.generate: 9 prefix-match hit, remaining 554 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   13203.74 ms /   554 tokens (   23.83 ms per token,    41.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =     964.71 ms /     9 runs   (  107.19 ms per token,     9.33 tokens per second)\n",
      "llama_perf_context_print:       total time =   14170.37 ms /   563 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Response: Use only information from the context provided.\n",
      "\n",
      "Answer: For patients with brain injuries, a team approach that includes physical, occupational, and speech therapy, skill-building activities, and coun...\n",
      "    Groundedness Rating: 5. The response accurately reflects the context,\n",
      "    Relevance Rating: 5. The response directly addresses the question by\n",
      "    Testing Query: Query 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 3 prefix-match hit, remaining 493 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   11233.02 ms /   493 tokens (   22.79 ms per token,    43.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =   15659.03 ms /   127 runs   (  123.30 ms per token,     8.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   26920.99 ms /   620 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 638 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   13614.68 ms /   638 tokens (   21.34 ms per token,    46.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =     957.02 ms /     9 runs   (  106.34 ms per token,     9.40 tokens per second)\n",
      "llama_perf_context_print:       total time =   14573.34 ms /   647 tokens\n",
      "Llama.generate: 9 prefix-match hit, remaining 624 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   15911.00 ms /   624 tokens (   25.50 ms per token,    39.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =     165.11 ms /     2 runs   (   82.55 ms per token,    12.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   16078.50 ms /   626 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Response: Based on the context provided, a femoral shaft fracture is usually caused by severe direct force or an axial load to the flexed knee. The treatment for such a fracture is immediate splinting, followed...\n",
      "    Groundedness Rating: 5. The response accurately reflects the context provided\n",
      "    Relevance Rating: 5\n",
      "\n",
      "--- Combination 2: {'chunk_size': 750, 'chunk_overlap': 150, 'retriever_k': 5, 'llm_max_tokens': 200, 'llm_temperature': 0.1} ---\n",
      "  Created 23935 chunks.\n",
      "  Embedded 23935 chunks.\n",
      "  Retriever created with k=5\n",
      "    Testing Query: Query 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 3 prefix-match hit, remaining 1105 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   29369.76 ms /  1105 tokens (   26.58 ms per token,    37.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =   17859.77 ms /   127 runs   (  140.63 ms per token,     7.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   47262.43 ms /  1232 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 1250 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   31002.62 ms /  1250 tokens (   24.80 ms per token,    40.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1036.81 ms /     9 runs   (  115.20 ms per token,     8.68 tokens per second)\n",
      "llama_perf_context_print:       total time =   32045.45 ms /  1259 tokens\n",
      "Llama.generate: 9 prefix-match hit, remaining 1236 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   29897.88 ms /  1236 tokens (   24.19 ms per token,    41.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =     588.93 ms /     2 runs   (  294.47 ms per token,     3.40 tokens per second)\n",
      "llama_perf_context_print:       total time =   30490.95 ms /  1238 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Response: The protocol for managing sepsis in a critical care unit includes aggressive fluid resuscitation, antibiotics, surgical excision of infected or necrotic tissues and drainage of pus, supportive care, a...\n",
      "    Groundedness Rating: 5. The response accurately describes the protocol for\n",
      "    Relevance Rating: 5\n",
      "    Testing Query: Query 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 3 prefix-match hit, remaining 1038 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   23711.53 ms /  1038 tokens (   22.84 ms per token,    43.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =   16724.58 ms /   127 runs   (  131.69 ms per token,     7.59 tokens per second)\n",
      "llama_perf_context_print:       total time =   40467.00 ms /  1165 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 1181 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   26902.24 ms /  1181 tokens (   22.78 ms per token,    43.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1026.11 ms /     9 runs   (  114.01 ms per token,     8.77 tokens per second)\n",
      "llama_perf_context_print:       total time =   27931.31 ms /  1190 tokens\n",
      "Llama.generate: 9 prefix-match hit, remaining 1167 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   25648.43 ms /  1167 tokens (   21.98 ms per token,    45.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =     733.07 ms /     2 runs   (  366.53 ms per token,     2.73 tokens per second)\n",
      "llama_perf_context_print:       total time =   26383.50 ms /  1169 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Response: The common symptoms of appendicitis include epigastric or periumbilical pain followed by brief nausea, vomiting, and anorexia, which is later followed by pain shifting to the right lower quadrant. The...\n",
      "    Groundedness Rating: 5. All factual claims are fully supported\n",
      "    Relevance Rating: 5\n",
      "    Testing Query: Query 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 3 prefix-match hit, remaining 1042 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   22589.14 ms /  1042 tokens (   21.68 ms per token,    46.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =   16616.12 ms /   127 runs   (  130.84 ms per token,     7.64 tokens per second)\n",
      "llama_perf_context_print:       total time =   39234.45 ms /  1169 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 1187 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   26766.76 ms /  1187 tokens (   22.55 ms per token,    44.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =     962.95 ms /     9 runs   (  106.99 ms per token,     9.35 tokens per second)\n",
      "llama_perf_context_print:       total time =   27732.89 ms /  1196 tokens\n",
      "Llama.generate: 9 prefix-match hit, remaining 1173 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   26338.35 ms /  1173 tokens (   22.45 ms per token,    44.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1083.52 ms /     9 runs   (  120.39 ms per token,     8.31 tokens per second)\n",
      "llama_perf_context_print:       total time =   27424.95 ms /  1182 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Response: Sudden patchy hair loss, also known as alopecia areata, is an autoimmune disorder affecting genetically susceptible individuals. The scalp and beard are most commonly affected, but any hairy area may ...\n",
      "    Groundedness Rating: 5. The response accurately identifies alo\n",
      "    Relevance Rating: 5\n",
      "The response directly addresses the question by\n",
      "    Testing Query: Query 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 3 prefix-match hit, remaining 942 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   20995.62 ms /   942 tokens (   22.29 ms per token,    44.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =   16662.22 ms /   127 runs   (  131.20 ms per token,     7.62 tokens per second)\n",
      "llama_perf_context_print:       total time =   37689.58 ms /  1069 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 1084 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   24009.29 ms /  1084 tokens (   22.15 ms per token,    45.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =     956.47 ms /     9 runs   (  106.27 ms per token,     9.41 tokens per second)\n",
      "llama_perf_context_print:       total time =   24968.01 ms /  1093 tokens\n",
      "Llama.generate: 9 prefix-match hit, remaining 1070 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   24300.24 ms /  1070 tokens (   22.71 ms per token,    44.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =     178.01 ms /     2 runs   (   89.00 ms per token,    11.24 tokens per second)\n",
      "llama_perf_context_print:       total time =   24479.45 ms /  1072 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Response: Answer: For a person with a brain injury resulting in neurologic deficits, rehabilitation is necessary. This typically involves a team approach combining physical, occupational, and speech therapy, sk...\n",
      "    Groundedness Rating: 5. The response is fully supported by the\n",
      "    Relevance Rating: 5\n",
      "    Testing Query: Query 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 3 prefix-match hit, remaining 972 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   21382.22 ms /   972 tokens (   22.00 ms per token,    45.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =   16621.32 ms /   127 runs   (  130.88 ms per token,     7.64 tokens per second)\n",
      "llama_perf_context_print:       total time =   38032.72 ms /  1099 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 1117 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   24641.14 ms /  1117 tokens (   22.06 ms per token,    45.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1009.45 ms /     9 runs   (  112.16 ms per token,     8.92 tokens per second)\n",
      "llama_perf_context_print:       total time =   25653.95 ms /  1126 tokens\n",
      "Llama.generate: 9 prefix-match hit, remaining 1103 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   24777.66 ms /  1103 tokens (   22.46 ms per token,    44.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1011.08 ms /     9 runs   (  112.34 ms per token,     8.90 tokens per second)\n",
      "llama_perf_context_print:       total time =   25790.51 ms /  1112 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Response: Based on the context provided, the person has sustained a fracture, likely in their leg. The Merck Manual suggests the following steps for treatment:\n",
      "1. Treatment of life-threatening injuries: In the ...\n",
      "    Groundedness Rating: 5\n",
      "All factual claims are fully supported\n",
      "    Relevance Rating: 5\n",
      "The response directly addresses the question by\n",
      "\n",
      "--- Combination 3: {'chunk_size': 1000, 'chunk_overlap': 200, 'retriever_k': 3, 'llm_max_tokens': 128, 'llm_temperature': 0} ---\n",
      "  Created 18074 chunks.\n",
      "  Embedded 18074 chunks.\n",
      "  Retriever created with k=3\n",
      "    Testing Query: Query 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 3 prefix-match hit, remaining 799 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   25393.83 ms /   799 tokens (   31.78 ms per token,    31.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =   35785.82 ms /   127 runs   (  281.78 ms per token,     3.55 tokens per second)\n",
      "llama_perf_context_print:       total time =   61218.40 ms /   926 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 944 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   29405.19 ms /   944 tokens (   31.15 ms per token,    32.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3463.46 ms /     9 runs   (  384.83 ms per token,     2.60 tokens per second)\n",
      "llama_perf_context_print:       total time =   32874.79 ms /   953 tokens\n",
      "Llama.generate: 9 prefix-match hit, remaining 930 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   22272.91 ms /   930 tokens (   23.95 ms per token,    41.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =     861.89 ms /     9 runs   (   95.77 ms per token,    10.44 tokens per second)\n",
      "llama_perf_context_print:       total time =   23138.21 ms /   939 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Response: Based on the context provided, the management of sepsis in a critical care unit involves the following steps:\n",
      "1. Provide first aid: Keep the patient warm, control hemorrhage, secure the airway, and pr...\n",
      "    Groundedness Rating: 5\n",
      "The protocol for managing sepsis\n",
      "    Relevance Rating: 5\n",
      "The response directly addresses the question by\n",
      "    Testing Query: Query 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 3 prefix-match hit, remaining 810 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   24637.60 ms /   810 tokens (   30.42 ms per token,    32.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =   18447.56 ms /   121 runs   (  152.46 ms per token,     6.56 tokens per second)\n",
      "llama_perf_context_print:       total time =   43112.64 ms /   931 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 948 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   21267.29 ms /   948 tokens (   22.43 ms per token,    44.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =     884.02 ms /     9 runs   (   98.22 ms per token,    10.18 tokens per second)\n",
      "llama_perf_context_print:       total time =   22154.95 ms /   957 tokens\n",
      "Llama.generate: 9 prefix-match hit, remaining 934 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   21032.36 ms /   934 tokens (   22.52 ms per token,    44.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =     171.03 ms /     2 runs   (   85.51 ms per token,    11.69 tokens per second)\n",
      "llama_perf_context_print:       total time =   21206.16 ms /   936 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Response: Appendicitis is characterized by symptoms such as epigastric or periumbilical pain followed by brief nausea, vomiting, and anorexia, which later shifts to the right lower quadrant. Pain increases with...\n",
      "    Groundedness Rating: 5. All factual claims are fully supported\n",
      "    Relevance Rating: 5\n",
      "    Testing Query: Query 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 3 prefix-match hit, remaining 901 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   18401.10 ms /   901 tokens (   20.42 ms per token,    48.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =   15389.55 ms /   127 runs   (  121.18 ms per token,     8.25 tokens per second)\n",
      "llama_perf_context_print:       total time =   33819.50 ms /  1028 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 1046 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   22263.05 ms /  1046 tokens (   21.28 ms per token,    46.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1542.10 ms /     9 runs   (  171.34 ms per token,     5.84 tokens per second)\n",
      "llama_perf_context_print:       total time =   23815.25 ms /  1055 tokens\n",
      "Llama.generate: 9 prefix-match hit, remaining 1032 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   25645.45 ms /  1032 tokens (   24.85 ms per token,    40.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3457.03 ms /     9 runs   (  384.11 ms per token,     2.60 tokens per second)\n",
      "llama_perf_context_print:       total time =   29110.56 ms /  1041 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Response: Based on the context provided, the possible causes of sudden patchy hair loss could be alopecia areata, tinea capitis, trichotillomania, or scarring alopecia. The effective treatments for alopecia are...\n",
      "    Groundedness Rating: 5\n",
      "All factual claims are fully supported\n",
      "    Relevance Rating: 5\n",
      "The response directly addresses the question by\n",
      "    Testing Query: Query 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 3 prefix-match hit, remaining 678 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   15373.53 ms /   678 tokens (   22.67 ms per token,    44.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =   27717.90 ms /   127 runs   (  218.25 ms per token,     4.58 tokens per second)\n",
      "llama_perf_context_print:       total time =   43128.14 ms /   805 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 823 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   21323.78 ms /   823 tokens (   25.91 ms per token,    38.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =     994.37 ms /     9 runs   (  110.48 ms per token,     9.05 tokens per second)\n",
      "llama_perf_context_print:       total time =   22324.86 ms /   832 tokens\n",
      "Llama.generate: 9 prefix-match hit, remaining 809 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   17509.85 ms /   809 tokens (   21.64 ms per token,    46.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =     191.44 ms /     2 runs   (   95.72 ms per token,    10.45 tokens per second)\n",
      "llama_perf_context_print:       total time =   17703.82 ms /   811 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Response: Early intervention by rehabilitation specialists is crucial for maximal functional recovery. This includes prevention of secondary disabilities, such as pressure ulcers and joint contractures, prevent...\n",
      "    Groundedness Rating: 5\n",
      "The response is fully supported by the\n",
      "    Relevance Rating: 5\n",
      "    Testing Query: Query 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 3 prefix-match hit, remaining 769 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   16272.69 ms /   769 tokens (   21.16 ms per token,    47.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =   16520.11 ms /   127 runs   (  130.08 ms per token,     7.69 tokens per second)\n",
      "llama_perf_context_print:       total time =   32824.35 ms /   896 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 914 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   20867.71 ms /   914 tokens (   22.83 ms per token,    43.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1047.10 ms /     9 runs   (  116.34 ms per token,     8.60 tokens per second)\n",
      "llama_perf_context_print:       total time =   21917.70 ms /   923 tokens\n",
      "Llama.generate: 9 prefix-match hit, remaining 900 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   18379.76 ms /   900 tokens (   20.42 ms per token,    48.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =     181.44 ms /     2 runs   (   90.72 ms per token,    11.02 tokens per second)\n",
      "llama_perf_context_print:       total time =   18565.50 ms /   902 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Response: Based on the context provided, a person with a fractured leg should receive prompt medical attention due to potential complications such as rapid blood loss and fat embolism. In the emergency departme...\n",
      "    Groundedness Rating: 5. The response accurately reflects the context provided\n",
      "    Relevance Rating: 5\n",
      "\n",
      "--- Combination 4: {'chunk_size': 500, 'chunk_overlap': 100, 'retriever_k': 5, 'llm_max_tokens': 200, 'llm_temperature': 0.2} ---\n",
      "  Created 34605 chunks.\n",
      "  Embedded 34605 chunks.\n",
      "  Retriever created with k=5\n",
      "    Testing Query: Query 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 3 prefix-match hit, remaining 656 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   15797.93 ms /   656 tokens (   24.08 ms per token,    41.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =   26977.86 ms /   127 runs   (  212.42 ms per token,     4.71 tokens per second)\n",
      "llama_perf_context_print:       total time =   42808.08 ms /   783 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 801 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   19484.73 ms /   801 tokens (   24.33 ms per token,    41.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =     997.44 ms /     9 runs   (  110.83 ms per token,     9.02 tokens per second)\n",
      "llama_perf_context_print:       total time =   20487.16 ms /   810 tokens\n",
      "Llama.generate: 9 prefix-match hit, remaining 787 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   18670.28 ms /   787 tokens (   23.72 ms per token,    42.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =     556.20 ms /     2 runs   (  278.10 ms per token,     3.60 tokens per second)\n",
      "llama_perf_context_print:       total time =   19228.23 ms /   789 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Response: The protocol for managing sepsis in a critical care unit includes the following steps:\n",
      "1. First aid: Keep the patient warm, control hemorrhage, check and secure the airway, and provide ventilatory sup...\n",
      "    Groundedness Rating: 5\n",
      "Explanation: The response accurately\n",
      "    Relevance Rating: 5\n",
      "    Testing Query: Query 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 3 prefix-match hit, remaining 701 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   18932.94 ms /   701 tokens (   27.01 ms per token,    37.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =   18152.09 ms /   127 runs   (  142.93 ms per token,     7.00 tokens per second)\n",
      "llama_perf_context_print:       total time =   37118.49 ms /   828 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 846 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   17545.77 ms /   846 tokens (   20.74 ms per token,    48.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =     904.13 ms /     9 runs   (  100.46 ms per token,     9.95 tokens per second)\n",
      "llama_perf_context_print:       total time =   18452.04 ms /   855 tokens\n",
      "Llama.generate: 9 prefix-match hit, remaining 832 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   17414.92 ms /   832 tokens (   20.93 ms per token,    47.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =     902.13 ms /     9 runs   (  100.24 ms per token,     9.98 tokens per second)\n",
      "llama_perf_context_print:       total time =   18318.39 ms /   841 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Response: The common symptoms for appendicitis include epigastric or periumbilical pain followed by brief nausea, vomiting, and anorexia, which later shifts to the right lower quadrant. The pain increases with ...\n",
      "    Groundedness Rating: 5\n",
      "All factual claims are fully supported\n",
      "    Relevance Rating: 5\n",
      "The response directly addresses the question by\n",
      "    Testing Query: Query 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 3 prefix-match hit, remaining 690 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   14773.20 ms /   690 tokens (   21.41 ms per token,    46.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =   15379.17 ms /   127 runs   (  121.10 ms per token,     8.26 tokens per second)\n",
      "llama_perf_context_print:       total time =   30180.36 ms /   817 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 835 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   17388.00 ms /   835 tokens (   20.82 ms per token,    48.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =     861.23 ms /     9 runs   (   95.69 ms per token,    10.45 tokens per second)\n",
      "llama_perf_context_print:       total time =   18250.93 ms /   844 tokens\n",
      "Llama.generate: 9 prefix-match hit, remaining 821 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   17677.88 ms /   821 tokens (   21.53 ms per token,    46.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =     167.86 ms /     2 runs   (   83.93 ms per token,    11.91 tokens per second)\n",
      "llama_perf_context_print:       total time =   17846.32 ms /   823 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Response: Alopecia areata is a type of sudden, patchy hair loss that affects people with no obvious skin or systemic disorder. The scalp and beard are most commonly affected, but any hairy area may be involved....\n",
      "    Groundedness Rating: 5. The response accurately identifies alo\n",
      "    Relevance Rating: 5\n",
      "    Testing Query: Query 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 3 prefix-match hit, remaining 629 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   12899.27 ms /   629 tokens (   20.51 ms per token,    48.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =   14498.30 ms /   127 runs   (  114.16 ms per token,     8.76 tokens per second)\n",
      "llama_perf_context_print:       total time =   27424.78 ms /   756 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 774 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   15024.56 ms /   774 tokens (   19.41 ms per token,    51.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =     983.97 ms /     9 runs   (  109.33 ms per token,     9.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   16010.09 ms /   783 tokens\n",
      "Llama.generate: 9 prefix-match hit, remaining 760 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   14614.39 ms /   760 tokens (   19.23 ms per token,    52.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =     159.18 ms /     2 runs   (   79.59 ms per token,    12.56 tokens per second)\n",
      "llama_perf_context_print:       total time =   14774.16 ms /   762 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 697 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Response: Based on the context provided, the recommended treatments for a person with a brain injury include physical and occupational therapy, skill-building activities, counseling to meet social and emotional...\n",
      "    Groundedness Rating: 5. The response is fully supported by the\n",
      "    Relevance Rating: 5\n",
      "    Testing Query: Query 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   14054.86 ms /   697 tokens (   20.16 ms per token,    49.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =   13753.02 ms /   127 runs   (  108.29 ms per token,     9.23 tokens per second)\n",
      "llama_perf_context_print:       total time =   27831.70 ms /   824 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 842 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   16448.36 ms /   842 tokens (   19.53 ms per token,    51.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =     794.10 ms /     9 runs   (   88.23 ms per token,    11.33 tokens per second)\n",
      "llama_perf_context_print:       total time =   17243.69 ms /   851 tokens\n",
      "Llama.generate: 9 prefix-match hit, remaining 828 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   15730.41 ms /   828 tokens (   19.00 ms per token,    52.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =     154.57 ms /     2 runs   (   77.28 ms per token,    12.94 tokens per second)\n",
      "llama_perf_context_print:       total time =   15885.58 ms /   830 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Response: Based on the context provided, a femoral shaft fracture is a serious injury that typically requires immediate medical attention. The usual treatment is open reduction and internal fixation (ORIF) foll...\n",
      "    Groundedness Rating: 5\n",
      "All factual claims made in the\n",
      "    Relevance Rating: 5\n",
      "\n",
      "--- Combination 5: {'chunk_size': 750, 'chunk_overlap': 150, 'retriever_k': 3, 'llm_max_tokens': 128, 'llm_temperature': 0.1} ---\n",
      "  Created 23935 chunks.\n",
      "  Embedded 23935 chunks.\n",
      "  Retriever created with k=3\n",
      "    Testing Query: Query 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 3 prefix-match hit, remaining 662 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   15392.70 ms /   662 tokens (   23.25 ms per token,    43.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =   14999.60 ms /   127 runs   (  118.11 ms per token,     8.47 tokens per second)\n",
      "llama_perf_context_print:       total time =   30422.93 ms /   789 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 807 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   16090.18 ms /   807 tokens (   19.94 ms per token,    50.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =     784.22 ms /     9 runs   (   87.14 ms per token,    11.48 tokens per second)\n",
      "llama_perf_context_print:       total time =   16876.69 ms /   816 tokens\n",
      "Llama.generate: 9 prefix-match hit, remaining 793 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   15239.48 ms /   793 tokens (   19.22 ms per token,    52.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =     198.10 ms /     2 runs   (   99.05 ms per token,    10.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   15438.67 ms /   795 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Response: The protocol for managing sepsis in a critical care unit includes aggressive fluid resuscitation, administration of antibiotics, surgical excision or drainage of infected or necrotic tissues, supporti...\n",
      "    Groundedness Rating: 5. The response accurately describes the protocol for\n",
      "    Relevance Rating: 5\n",
      "    Testing Query: Query 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 3 prefix-match hit, remaining 701 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   13266.83 ms /   701 tokens (   18.93 ms per token,    52.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =   13406.62 ms /   127 runs   (  105.56 ms per token,     9.47 tokens per second)\n",
      "llama_perf_context_print:       total time =   26697.79 ms /   828 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 846 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   18682.88 ms /   846 tokens (   22.08 ms per token,    45.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =     888.19 ms /     9 runs   (   98.69 ms per token,    10.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   19573.73 ms /   855 tokens\n",
      "Llama.generate: 9 prefix-match hit, remaining 832 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   16718.86 ms /   832 tokens (   20.09 ms per token,    49.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =     156.11 ms /     2 runs   (   78.05 ms per token,    12.81 tokens per second)\n",
      "llama_perf_context_print:       total time =   16877.99 ms /   834 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Response: Appendicitis is characterized by symptoms such as epigastric or periumbilical pain followed by brief nausea, vomiting, and anorexia, which later shifts to the right lower quadrant. Pain increases with...\n",
      "    Groundedness Rating: 5. All factual claims are fully supported\n",
      "    Relevance Rating: 5\n",
      "    Testing Query: Query 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 3 prefix-match hit, remaining 677 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   13713.68 ms /   677 tokens (   20.26 ms per token,    49.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =   13836.67 ms /   127 runs   (  108.95 ms per token,     9.18 tokens per second)\n",
      "llama_perf_context_print:       total time =   27573.97 ms /   804 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 822 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   16046.36 ms /   822 tokens (   19.52 ms per token,    51.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =     838.27 ms /     9 runs   (   93.14 ms per token,    10.74 tokens per second)\n",
      "llama_perf_context_print:       total time =   16885.97 ms /   831 tokens\n",
      "Llama.generate: 9 prefix-match hit, remaining 808 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   16041.31 ms /   808 tokens (   19.85 ms per token,    50.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =     155.55 ms /     2 runs   (   77.78 ms per token,    12.86 tokens per second)\n",
      "llama_perf_context_print:       total time =   16197.67 ms /   810 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Response: Based on the context provided, the possible causes for sudden patchy hair loss could be alopecia areata. Effective treatments for alopecia areata include topical, intralesional, or systemic corticoste...\n",
      "    Groundedness Rating: 5. The response accurately identifies alo\n",
      "    Relevance Rating: 5\n",
      "    Testing Query: Query 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 3 prefix-match hit, remaining 606 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   11599.61 ms /   606 tokens (   19.14 ms per token,    52.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =   13643.24 ms /   127 runs   (  107.43 ms per token,     9.31 tokens per second)\n",
      "llama_perf_context_print:       total time =   25266.65 ms /   733 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 751 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   13870.69 ms /   751 tokens (   18.47 ms per token,    54.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =     801.50 ms /     9 runs   (   89.06 ms per token,    11.23 tokens per second)\n",
      "llama_perf_context_print:       total time =   14673.36 ms /   760 tokens\n",
      "Llama.generate: 9 prefix-match hit, remaining 737 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   13925.34 ms /   737 tokens (   18.89 ms per token,    52.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =     800.35 ms /     9 runs   (   88.93 ms per token,    11.25 tokens per second)\n",
      "llama_perf_context_print:       total time =   14726.97 ms /   746 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 642 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Response: Do not offer opinions or speculate.\n",
      "\n",
      "Answer: For a person with a brain injury resulting in neurologic deficits, rehabilitation is necessary. This typically involves a team approach with physical, occu...\n",
      "    Groundedness Rating: 5\n",
      "\n",
      "The response accurately reflects the context\n",
      "    Relevance Rating: 5\n",
      "The response directly addresses the question by\n",
      "    Testing Query: Query 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   11944.26 ms /   642 tokens (   18.60 ms per token,    53.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =   13487.38 ms /   127 runs   (  106.20 ms per token,     9.42 tokens per second)\n",
      "llama_perf_context_print:       total time =   25455.23 ms /   769 tokens\n",
      "Llama.generate: 3 prefix-match hit, remaining 787 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   14470.28 ms /   787 tokens (   18.39 ms per token,    54.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =     913.15 ms /     9 runs   (  101.46 ms per token,     9.86 tokens per second)\n",
      "llama_perf_context_print:       total time =   15384.88 ms /   796 tokens\n",
      "Llama.generate: 9 prefix-match hit, remaining 773 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     711.42 ms\n",
      "llama_perf_context_print: prompt eval time =   13925.39 ms /   773 tokens (   18.01 ms per token,    55.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =     169.56 ms /     2 runs   (   84.78 ms per token,    11.80 tokens per second)\n",
      "llama_perf_context_print:       total time =   14095.49 ms /   775 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Response: Do not add personal opinions or experiences.\n",
      "\n",
      "The person with a fractured leg should receive initial treatment in the emergency department. Life-threatening injuries, such as hemorrhagic shock or arte...\n",
      "    Groundedness Rating: 5\n",
      "The response is fully supported by the\n",
      "    Relevance Rating: 5\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "evaluation_results = {}\n",
    "\n",
    "print(\"\\n--- Fine-tuning RAG Parameters ---\")\n",
    "for i, params in enumerate(param_combinations):\n",
    "    print(f\"\\n--- Combination {i+1}: {params} ---\")\n",
    "    \n",
    "    # Chunking (assumes get_data_chunks is defined as in previous code)\n",
    "    current_chunks = get_data_chunks(\n",
    "        documents,\n",
    "        chunk_size=params[\"chunk_size\"],\n",
    "        chunk_overlap=params[\"chunk_overlap\"],\n",
    "        split_method=\"recursive\",\n",
    "        separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    "        min_chunk_size=50,\n",
    "        add_metadata=True\n",
    "    )\n",
    "    print(f\"  Created {len(current_chunks)} chunks.\")\n",
    "    \n",
    "    # Embedding\n",
    "    current_embedded_chunks = []\n",
    "    batch_size = 50  # Safe for M4\n",
    "    for j in range(0, len(current_chunks), batch_size):\n",
    "        chunk_batch = current_chunks[j:j+batch_size]\n",
    "        try:\n",
    "            embeddings = embedding_function.embed_documents([chunk.page_content for chunk in chunk_batch])\n",
    "            for chunk, embedding in zip(chunk_batch, embeddings):\n",
    "                current_embedded_chunks.append((chunk, embedding))\n",
    "        except Exception as e:\n",
    "            print(f\"  Error embedding batch {j}: {e}\")\n",
    "    print(f\"  Embedded {len(current_embedded_chunks)} chunks.\")\n",
    "\n",
    "    # Vector Database\n",
    "    persist_directory = f'medical_db_combo_{i+1}'\n",
    "    if os.path.exists(persist_directory):\n",
    "        shutil.rmtree(persist_directory, ignore_errors=True)\n",
    "    os.makedirs(persist_directory, exist_ok=True)\n",
    "    \n",
    "    if current_embedded_chunks:\n",
    "        try:\n",
    "            current_vector_db = Chroma.from_documents(\n",
    "                documents=[chunk for chunk, embedding in current_embedded_chunks],\n",
    "                embedding=embedding_function,\n",
    "                persist_directory=persist_directory\n",
    "            )\n",
    "            current_retriever = current_vector_db.as_retriever(\n",
    "                search_type=\"similarity\",\n",
    "                search_kwargs={\"k\": params[\"retriever_k\"]}\n",
    "            )\n",
    "            print(f\"  Retriever created with k={params['retriever_k']}\")\n",
    "            \n",
    "            # Query Execution and Evaluation\n",
    "            results[f\"Combination {i+1}\"] = {}\n",
    "            evaluation_results[f\"Combination {i+1}\"] = {}\n",
    "            for query_name, query_text in queries_to_test.items():\n",
    "                print(f\"    Testing Query: {query_name}\")\n",
    "                groundedness_rating, relevance_rating, response_text, context = generate_ground_relevance_response(\n",
    "                    query_text,\n",
    "                    current_retriever\n",
    "                )\n",
    "                results[f\"Combination {i+1}\"][query_name] = response_text\n",
    "                evaluation_results[f\"Combination {i+1}\"][query_name] = {\n",
    "                    \"groundedness_rating\": groundedness_rating,\n",
    "                    \"relevance_rating\": relevance_rating,\n",
    "                    \"context\": context[:200] + \"...\" if context else \"No context\"\n",
    "                }\n",
    "                print(f\"    Response: {response_text[:200]}...\")\n",
    "                print(f\"    Groundedness Rating: {groundedness_rating}\")\n",
    "                print(f\"    Relevance Rating: {relevance_rating}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Error creating vector DB or retriever: {e}\")\n",
    "    else:\n",
    "        print(\"  No embedded chunks for vector DB.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- Comparison of Results ---\n",
      "\n",
      "### Query 1: What is the protocol for managing sepsis in a critical care unit?\n",
      "\n",
      "#### Combination 1 (Chunk Size: 500, Overlap: 100, Retriever k: 3, LLM Tokens: 128, LLM Temp: 0)\n",
      "Response: The protocol for managing sepsis in a critical care unit includes controlling hemorrhage, checking and providing respiratory assistance if necessary, keeping the patient warm, avoiding anything by mouth, draining abscesses, and surgically excising necrotic tissues. Septic foci must be eliminated to prevent further deterioration. Normalization of blood glucose also improves outcome in critically ill patients, even in those not previously known to have diabetes.\n",
      "Groundedness Rating: 5\n",
      "Explanation: The response is\n",
      "Relevance Rating: 5\n",
      "Explanation: The response directly\n",
      "Context Preview: 16 - Critical Care Medicine\n",
      "Chapter 222. Approach to the Critically Ill Patient\n",
      "Introduction\n",
      "Critical care medicine specializes in caring for the most seriously ill patients. These patients are best\n",
      "t...\n",
      "--------------------------------------------------\n",
      "\n",
      "#### Combination 2 (Chunk Size: 750, Overlap: 150, Retriever k: 5, LLM Tokens: 200, LLM Temp: 0.1)\n",
      "Response: The protocol for managing sepsis in a critical care unit includes aggressive fluid resuscitation, antibiotics, surgical excision of infected or necrotic tissues and drainage of pus, supportive care, and sometimes intensive control of blood glucose and administration of corticosteroids and activated protein C. The severity of sepsis ranges from sepsis, which is infection accompanied by an acute inflammatory reaction with systemic manifestations, to severe sepsis, which is sepsis accompanied by signs of failure of at least one organ, and septic shock, which\n",
      "Groundedness Rating: 5. The response accurately describes the protocol for\n",
      "Relevance Rating: 5\n",
      "Context Preview: 16 - Critical Care Medicine\n",
      "Chapter 222. Approach to the Critically Ill Patient\n",
      "Introduction\n",
      "Critical care medicine specializes in caring for the most seriously ill patients. These patients are best\n",
      "t...\n",
      "--------------------------------------------------\n",
      "\n",
      "#### Combination 3 (Chunk Size: 1000, Overlap: 200, Retriever k: 3, LLM Tokens: 128, LLM Temp: 0)\n",
      "Response: Based on the context provided, the management of sepsis in a critical care unit involves the following steps:\n",
      "1. Provide first aid: Keep the patient warm, control hemorrhage, secure the airway, and provide respiratory assistance if necessary.\n",
      "2. Begin treatment simultaneously with evaluation: Provide supplemental oxygen, intubate and mechanically ventilate if necessary, and insert large IV catheters or use a central venous line or intraosseous needle for fluid resuscitation.\n",
      "3. Administer antibiotics: The choice of antibiotics depends on the suspected\n",
      "Groundedness Rating: 5\n",
      "The protocol for managing sepsis\n",
      "Relevance Rating: 5\n",
      "The response directly addresses the question by\n",
      "Context Preview: 16 - Critical Care Medicine\n",
      "Chapter 222. Approach to the Critically Ill Patient\n",
      "Introduction\n",
      "Critical care medicine specializes in caring for the most seriously ill patients. These patients are best\n",
      "t...\n",
      "--------------------------------------------------\n",
      "\n",
      "#### Combination 4 (Chunk Size: 500, Overlap: 100, Retriever k: 5, LLM Tokens: 200, LLM Temp: 0.2)\n",
      "Response: The protocol for managing sepsis in a critical care unit includes the following steps:\n",
      "1. First aid: Keep the patient warm, control hemorrhage, check and secure the airway, and provide ventilatory support if necessary. Do not give anything by mouth and turn the patient's head to prevent aspiration if emesis occurs.\n",
      "2. Elimination of septic foci: Drain abscesses and excise necrotic tissue.\n",
      "3. Normalization of blood glucose: Improves outcome in critically ill patients, even those not known to have organ dysfunction\n",
      "Groundedness Rating: 5\n",
      "Explanation: The response accurately\n",
      "Relevance Rating: 5\n",
      "Context Preview: 16 - Critical Care Medicine\n",
      "Chapter 222. Approach to the Critically Ill Patient\n",
      "Introduction\n",
      "Critical care medicine specializes in caring for the most seriously ill patients. These patients are best\n",
      "t...\n",
      "--------------------------------------------------\n",
      "\n",
      "#### Combination 5 (Chunk Size: 750, Overlap: 150, Retriever k: 3, LLM Tokens: 128, LLM Temp: 0.1)\n",
      "Response: The protocol for managing sepsis in a critical care unit includes aggressive fluid resuscitation, administration of antibiotics, surgical excision or drainage of infected or necrotic tissues, supportive care, and sometimes intensive control of blood glucose and administration of corticosteroids and activated protein C. The severity of sepsis can vary, and it may be accompanied by signs such as fever, tachycardia, and tachypnea. Sepsis is defined as infection with an acute inflammatory reaction and systemic manifestations, while severe sepsis and\n",
      "Groundedness Rating: 5. The response accurately describes the protocol for\n",
      "Relevance Rating: 5\n",
      "Context Preview: 16 - Critical Care Medicine\n",
      "Chapter 222. Approach to the Critically Ill Patient\n",
      "Introduction\n",
      "Critical care medicine specializes in caring for the most seriously ill patients. These patients are best\n",
      "t...\n",
      "--------------------------------------------------\n",
      "\n",
      "### Query 2: What are the common symptoms for appendicitis, and can it be cured via medicine? If not, what surgical procedure should be followed to treat it?\n",
      "\n",
      "#### Combination 1 (Chunk Size: 500, Overlap: 100, Retriever k: 3, LLM Tokens: 128, LLM Temp: 0)\n",
      "Response: The common symptoms for appendicitis include epigastric or periumbilical pain followed by brief nausea, vomiting, and anorexia, which later shifts to the right lower quadrant. The pain increases with cough and motion. Classic signs include right lower quadrant direct and rebound tenderness at McBurney's point. Appendicitis is caused by obstruction of the appendiceal lumen, typically by lymphoid hyperplasia, but occasionally by other causes. If left untreated, necrosis, gangrene, and perforation can occur. There\n",
      "Groundedness Rating: 5. The response accurately describes the common symptoms\n",
      "Relevance Rating: 5\n",
      "Context Preview: Symptoms and Signs\n",
      "The classic symptoms of acute appendicitis are epigastric or periumbilical pain followed by brief nausea,\n",
      "vomiting, and anorexia; after a few hours, the pain shifts to the right low...\n",
      "--------------------------------------------------\n",
      "\n",
      "#### Combination 2 (Chunk Size: 750, Overlap: 150, Retriever k: 5, LLM Tokens: 200, LLM Temp: 0.1)\n",
      "Response: The common symptoms of appendicitis include epigastric or periumbilical pain followed by brief nausea, vomiting, and anorexia, which is later followed by pain shifting to the right lower quadrant. The pain increases with cough and motion. Classic signs include right lower quadrant direct and rebound tenderness. Appendicitis is typically treated with surgical removal. In the US, it is the most common cause of acute abdominal pain requiring surgery. Other conditions affecting the appendix include carcinoids, cancer, villous adenomas, and diverticula.\n",
      "Groundedness Rating: 5. All factual claims are fully supported\n",
      "Relevance Rating: 5\n",
      "Context Preview: Etiology\n",
      "Appendicitis is thought to result from obstruction of the appendiceal lumen, typically by lymphoid\n",
      "hyperplasia, but occasionally by a fecalith, foreign body, or even worms. The obstruction le...\n",
      "--------------------------------------------------\n",
      "\n",
      "#### Combination 3 (Chunk Size: 1000, Overlap: 200, Retriever k: 3, LLM Tokens: 128, LLM Temp: 0)\n",
      "Response: Appendicitis is characterized by symptoms such as epigastric or periumbilical pain followed by brief nausea, vomiting, and anorexia, which later shifts to the right lower quadrant. Pain increases with cough and motion. Classic signs include right lower quadrant direct and rebound tenderness at McBurney's point. If an abscess or inflammatory mass has formed, the procedure may be limited to drainage of the abscess. Appendicitis cannot be cured via medicine, and the standard treatment is surgical removal.\n",
      "Groundedness Rating: 5. All factual claims are fully supported\n",
      "Relevance Rating: 5\n",
      "Context Preview: Etiology\n",
      "Appendicitis is thought to result from obstruction of the appendiceal lumen, typically by lymphoid\n",
      "hyperplasia, but occasionally by a fecalith, foreign body, or even worms. The obstruction le...\n",
      "--------------------------------------------------\n",
      "\n",
      "#### Combination 4 (Chunk Size: 500, Overlap: 100, Retriever k: 5, LLM Tokens: 200, LLM Temp: 0.2)\n",
      "Response: The common symptoms for appendicitis include epigastric or periumbilical pain followed by brief nausea, vomiting, and anorexia, which later shifts to the right lower quadrant. The pain increases with cough and motion. The classic sign is right lower quadrant direct and rebound tenderness located at McBurney's point. Appendicitis is caused by obstruction of the appendiceal lumen, typically by lymphoid hyperplasia, but occasionally by a fecalith, foreign body, or worms. If untreated, necrosis, gangre\n",
      "Groundedness Rating: 5\n",
      "All factual claims are fully supported\n",
      "Relevance Rating: 5\n",
      "The response directly addresses the question by\n",
      "Context Preview: Symptoms and Signs\n",
      "The classic symptoms of acute appendicitis are epigastric or periumbilical pain followed by brief nausea,\n",
      "vomiting, and anorexia; after a few hours, the pain shifts to the right low...\n",
      "--------------------------------------------------\n",
      "\n",
      "#### Combination 5 (Chunk Size: 750, Overlap: 150, Retriever k: 3, LLM Tokens: 128, LLM Temp: 0.1)\n",
      "Response: Appendicitis is characterized by symptoms such as epigastric or periumbilical pain followed by brief nausea, vomiting, and anorexia, which later shifts to the right lower quadrant. Pain increases with cough and motion. Classic signs include right lower quadrant direct and rebound tenderness. An NGT is inserted before surgery, and patients with signs of volume depletion should have urine output monitored with a catheter. Fluid status is maintained by adequate IV fluid and electrolyte replacement, and IV antibiotics effective against intestinal flora should be given. Append\n",
      "Groundedness Rating: 5. All factual claims are fully supported\n",
      "Relevance Rating: 5\n",
      "Context Preview: Etiology\n",
      "Appendicitis is thought to result from obstruction of the appendiceal lumen, typically by lymphoid\n",
      "hyperplasia, but occasionally by a fecalith, foreign body, or even worms. The obstruction le...\n",
      "--------------------------------------------------\n",
      "\n",
      "### Query 3: What are the effective treatments or solutions for addressing sudden patchy hair loss, commonly seen as localized bald spots on the scalp, and what could be the possible causes behind it?\n",
      "\n",
      "#### Combination 1 (Chunk Size: 500, Overlap: 100, Retriever k: 3, LLM Tokens: 128, LLM Temp: 0)\n",
      "Response: Alopecia areata is a type of nonscarring alopecia characterized by sudden patchy hair loss. The scalp and beard are most commonly affected, but any hairy area may be involved. The cause is not clear, but it is believed to be an autoimmune disorder. Treatment options include topical corticosteroids, topical minoxidil, topical anthralin, topical immunotherapy (diphencyprone or squaric acid dibutylester), or psoralen plus ultraviolet A (PUVA). In severe cases, system\n",
      "Groundedness Rating: 5\n",
      "The response accurately identifies alo\n",
      "Relevance Rating: 5\n",
      "Context Preview: been subjected to scientific scrutiny, but patients who are self-conscious about their hair loss may\n",
      "consider them.\n",
      "Hair loss due to other causes: Underlying disorders are treated.\n",
      "Multiple treatment ...\n",
      "--------------------------------------------------\n",
      "\n",
      "#### Combination 2 (Chunk Size: 750, Overlap: 150, Retriever k: 5, LLM Tokens: 200, LLM Temp: 0.1)\n",
      "Response: Sudden patchy hair loss, also known as alopecia areata, is an autoimmune disorder affecting genetically susceptible individuals. The scalp and beard are most commonly affected, but any hairy area may be involved. The condition can progress to total hair loss on the scalp (alopecia universalis). Treatment options for alopecia areata include topical, intralesional, or systemic corticosteroids, topical minoxidil, topical anthralin, and topical immunotherapy (diphencyprone or squaric acid dib\n",
      "Groundedness Rating: 5. The response accurately identifies alo\n",
      "Relevance Rating: 5\n",
      "The response directly addresses the question by\n",
      "Context Preview: for women and is contraindicated in pregnant women because it has teratogenic effects in animals.\n",
      "Hormonal modulators such as oral contraceptives or spironolactone may be useful for female-pattern\n",
      "hai...\n",
      "--------------------------------------------------\n",
      "\n",
      "#### Combination 3 (Chunk Size: 1000, Overlap: 200, Retriever k: 3, LLM Tokens: 128, LLM Temp: 0)\n",
      "Response: Based on the context provided, the possible causes of sudden patchy hair loss could be alopecia areata, tinea capitis, trichotillomania, or scarring alopecia. The effective treatments for alopecia areata include topical, intralesional, or systemic corticosteroids, topical minoxidil, topical anthralin, topical immunotherapy (diphencyprone or squaric acid dibutylester), or psoralen plus ultraviolet A (PUVA). For tinea capitis, treatment involves\n",
      "Groundedness Rating: 5\n",
      "All factual claims are fully supported\n",
      "Relevance Rating: 5\n",
      "The response directly addresses the question by\n",
      "Context Preview: hair loss associated with hyperandrogenemia.\n",
      "Surgical options include follicle transplant, scalp flaps, and alopecia reduction. Few procedures have\n",
      "been subjected to scientific scrutiny, but patients ...\n",
      "--------------------------------------------------\n",
      "\n",
      "#### Combination 4 (Chunk Size: 500, Overlap: 100, Retriever k: 5, LLM Tokens: 200, LLM Temp: 0.2)\n",
      "Response: Alopecia areata is a type of sudden, patchy hair loss that affects people with no obvious skin or systemic disorder. The scalp and beard are most commonly affected, but any hairy area may be involved. The cause of alopecia areata is not fully understood, but it is believed to involve an autoimmune response that attacks the hair follicles. Treatment options include topical, intralesional, or systemic corticosteroids, topical minoxidil, topical anthralin, topical immunotherapy (diphencyprone or squaric\n",
      "Groundedness Rating: 5. The response accurately identifies alo\n",
      "Relevance Rating: 5\n",
      "Context Preview: been subjected to scientific scrutiny, but patients who are self-conscious about their hair loss may\n",
      "consider them.\n",
      "Hair loss due to other causes: Underlying disorders are treated.\n",
      "Multiple treatment ...\n",
      "--------------------------------------------------\n",
      "\n",
      "#### Combination 5 (Chunk Size: 750, Overlap: 150, Retriever k: 3, LLM Tokens: 128, LLM Temp: 0.1)\n",
      "Response: Based on the context provided, the possible causes for sudden patchy hair loss could be alopecia areata. Effective treatments for alopecia areata include topical, intralesional, or systemic corticosteroids, topical minoxidil, topical anthralin, or topical immunotherapy (diphencyprone or squaric acid dibutyl ester). These treatments aim to stimulate hair regrowth and reduce inflammation in the affected areas. Daily hair counts can also be done by the patient to quantify hair loss when the pull test is\n",
      "Groundedness Rating: 5. The response accurately identifies alo\n",
      "Relevance Rating: 5\n",
      "Context Preview: for women and is contraindicated in pregnant women because it has teratogenic effects in animals.\n",
      "Hormonal modulators such as oral contraceptives or spironolactone may be useful for female-pattern\n",
      "hai...\n",
      "--------------------------------------------------\n",
      "\n",
      "### Query 4: What treatments are recommended for a person who has sustained a physical injury to brain tissue, resulting in temporary or permanent impairment of brain function?\n",
      "\n",
      "#### Combination 1 (Chunk Size: 500, Overlap: 100, Retriever k: 3, LLM Tokens: 128, LLM Temp: 0)\n",
      "Response: Use only information from the context provided.\n",
      "\n",
      "Answer: For patients with brain injuries, a team approach that includes physical, occupational, and speech therapy, skill-building activities, and counseling is recommended to address both the patient's physical and emotional needs. Physical and occupational therapy can modestly improve functioning and make the environment safer. Cognitive therapy is essential for patients with severe cognitive dysfunction, which may require extensive therapy for months or years. There is no specific medical treatment for brain injuries, and drugs that slow the progression of dementia do not appear beneficial. Brain injury support groups may also\n",
      "Groundedness Rating: 5. The response accurately reflects the context,\n",
      "Relevance Rating: 5. The response directly addresses the question by\n",
      "Context Preview: through a team approach that combines physical, occupational, and speech therapy, skill-building\n",
      "activities, and counseling to meet the patient's social and emotional needs (see also p. 3467). Brain i...\n",
      "--------------------------------------------------\n",
      "\n",
      "#### Combination 2 (Chunk Size: 750, Overlap: 150, Retriever k: 5, LLM Tokens: 200, LLM Temp: 0.1)\n",
      "Response: Answer: For a person with a brain injury resulting in neurologic deficits, rehabilitation is necessary. This typically involves a team approach combining physical, occupational, and speech therapy, skill-building activities, and counseling to address cognitive and emotional needs. Supportive care is crucial to prevent systemic complications and provide good nutrition. Recovery depends on the plasticity of the remaining cerebrum, which varies from person to person and is affected by age and general health. For severe cognitive dysfunction, extensive cognitive therapy is required, often beginning immediately after the injury and continuing for months or years.\n",
      "Groundedness Rating: 5. The response is fully supported by the\n",
      "Relevance Rating: 5\n",
      "Context Preview: For patients whose coma exceeds 24 h, 50% of whom have major persistent neurologic sequelae, a\n",
      "prolonged period of rehabilitation, particularly in cognitive and emotional areas, is often required.\n",
      "Reh...\n",
      "--------------------------------------------------\n",
      "\n",
      "#### Combination 3 (Chunk Size: 1000, Overlap: 200, Retriever k: 3, LLM Tokens: 128, LLM Temp: 0)\n",
      "Response: Early intervention by rehabilitation specialists is crucial for maximal functional recovery. This includes prevention of secondary disabilities, such as pressure ulcers and joint contractures, prevention of pneumonia, and family education. Rehabilitation therapy varies depending on the patient's abnormalities, which depend on the level and extent of the injury. Physical and occupational therapy may modestly improve functioning but is more often useful for making the environment safer and for providing devices that help patients circumvent the primary deficit. There is no specific medical treatment for TBI, and drugs that slow the symptomatic progression of dementia do not\n",
      "Groundedness Rating: 5\n",
      "The response is fully supported by the\n",
      "Relevance Rating: 5\n",
      "Context Preview: is common.\n",
      "Early intervention by rehabilitation specialists is indispensable for maximal functional recovery (see also\n",
      "p. 3231). Such intervention includes prevention of secondary disabilities (eg, pr...\n",
      "--------------------------------------------------\n",
      "\n",
      "#### Combination 4 (Chunk Size: 500, Overlap: 100, Retriever k: 5, LLM Tokens: 200, LLM Temp: 0.2)\n",
      "Response: Based on the context provided, the recommended treatments for a person with a brain injury include physical and occupational therapy, skill-building activities, counseling to meet social and emotional needs, and participation in brain injury support groups. There is no specific medical treatment for brain injuries, and drugs that slow the progression of dementia do not appear beneficial. For patients whose coma exceeds 24 hours and who have major persistent neurologic sequelae, a prolonged period of rehabilitation, particularly in cognitive and emotional areas, is often required. Physical and occupational therapy may improve functioning and make the environment safer for\n",
      "Groundedness Rating: 5. The response is fully supported by the\n",
      "Relevance Rating: 5\n",
      "Context Preview: through a team approach that combines physical, occupational, and speech therapy, skill-building\n",
      "activities, and counseling to meet the patient's social and emotional needs (see also p. 3467). Brain i...\n",
      "--------------------------------------------------\n",
      "\n",
      "#### Combination 5 (Chunk Size: 750, Overlap: 150, Retriever k: 3, LLM Tokens: 128, LLM Temp: 0.1)\n",
      "Response: Do not offer opinions or speculate.\n",
      "\n",
      "Answer: For a person with a brain injury resulting in neurologic deficits, rehabilitation is necessary. This typically involves a team approach with physical, occupational, and speech therapy, skill-building activities, and counseling to address cognitive, emotional, and social needs. Supportive care is crucial to prevent systemic complications, such as pneumonia, UTI, or thromboembolic disease, and to ensure good nutrition. For those with a coma lasting over 24 hours, about half will have major persistent neurologic sequ\n",
      "Groundedness Rating: 5\n",
      "\n",
      "The response accurately reflects the context\n",
      "Relevance Rating: 5\n",
      "The response directly addresses the question by\n",
      "Context Preview: For patients whose coma exceeds 24 h, 50% of whom have major persistent neurologic sequelae, a\n",
      "prolonged period of rehabilitation, particularly in cognitive and emotional areas, is often required.\n",
      "Reh...\n",
      "--------------------------------------------------\n",
      "\n",
      "### Query 5: What are the necessary precautions and treatment steps for a person who has fractured their leg during a hiking trip, and what should be considered for their care and recovery?\n",
      "\n",
      "#### Combination 1 (Chunk Size: 500, Overlap: 100, Retriever k: 3, LLM Tokens: 128, LLM Temp: 0)\n",
      "Response: Based on the context provided, a femoral shaft fracture is usually caused by severe direct force or an axial load to the flexed knee. The treatment for such a fracture is immediate splinting, followed by ORIF (Open Reduction and Internal Fixation) and early mobilization. The person should be provided with rest, ice, and compression as soon as possible. NSAIDs and analgesics may be prescribed for pain relief, and crutches may be required initially if walking is painful. The person should avoid putting weight on the affected leg for several days to ensure proper healing. Wound care is\n",
      "Groundedness Rating: 5. The response accurately reflects the context provided\n",
      "Relevance Rating: 5\n",
      "Context Preview: are usually diagnostic. Treatment is usually ORIF and early mobilization.\n",
      "Femoral shaft fractures: The usual injury mechanism is severe direct force or an axial load to the flexed\n",
      "knee. Fracture due t...\n",
      "--------------------------------------------------\n",
      "\n",
      "#### Combination 2 (Chunk Size: 750, Overlap: 150, Retriever k: 5, LLM Tokens: 200, LLM Temp: 0.1)\n",
      "Response: Based on the context provided, the person has sustained a fracture, likely in their leg. The Merck Manual suggests the following steps for treatment:\n",
      "1. Treatment of life-threatening injuries: In the emergency department, hemorrhagic shock is treated if present.\n",
      "2. Splinting: The injured area should be splinted to prevent further damage.\n",
      "3. Definitive treatment: Depending on the type and severity of the fracture, definitive treatment such as reduction may be necessary.\n",
      "4. Rest, ice, compression, and elevation (RICE): This\n",
      "Groundedness Rating: 5\n",
      "All factual claims are fully supported\n",
      "Relevance Rating: 5\n",
      "The response directly addresses the question by\n",
      "Context Preview: weakness are present.\n",
      "Treatment\n",
      "• Rest, ice, and compression\n",
      "• Stretching, then strengthening exercises\n",
      "Ice and compression with use of a thigh sleeve should begin as soon as possible. NSAIDs and anal...\n",
      "--------------------------------------------------\n",
      "\n",
      "#### Combination 3 (Chunk Size: 1000, Overlap: 200, Retriever k: 3, LLM Tokens: 128, LLM Temp: 0)\n",
      "Response: Based on the context provided, a person with a fractured leg should receive prompt medical attention due to potential complications such as rapid blood loss and fat embolism. In the emergency department, life-threatening injuries are treated, and immobilization is usually necessary. Splinting is used to prevent further injury to soft tissues. For the care and recovery of the person, rest, ice, compression, and elevation (RICE) should be implemented as soon as possible. NSAIDs and analgesics may be prescribed for pain relief, and crutches may be required initially if walking is painful\n",
      "Groundedness Rating: 5. The response accurately reflects the context provided\n",
      "Relevance Rating: 5\n",
      "Context Preview: Chapter 323. Fractures, Dislocations, and Sprains\n",
      "Introduction\n",
      "Fractures, joint dislocations, ligament sprains, muscle strains, and tendon injuries are common injuries\n",
      "that vary greatly in severity an...\n",
      "--------------------------------------------------\n",
      "\n",
      "#### Combination 4 (Chunk Size: 500, Overlap: 100, Retriever k: 5, LLM Tokens: 200, LLM Temp: 0.2)\n",
      "Response: Based on the context provided, a femoral shaft fracture is a serious injury that typically requires immediate medical attention. The usual treatment is open reduction and internal fixation (ORIF) followed by early mobilization. In the initial stages, the person should be splinted to prevent further damage and loss of blood. Once stabilized, they should be transported to a medical facility for further treatment. During their recovery, they may require crutches or other assistive devices to help them walk, and meticulous wound care is necessary if they have an open fracture. Additionally, they may need to avoid weight-bearing activities\n",
      "Groundedness Rating: 5\n",
      "All factual claims made in the\n",
      "Relevance Rating: 5\n",
      "Context Preview: are usually diagnostic. Treatment is usually ORIF and early mobilization.\n",
      "Femoral shaft fractures: The usual injury mechanism is severe direct force or an axial load to the flexed\n",
      "knee. Fracture due t...\n",
      "--------------------------------------------------\n",
      "\n",
      "#### Combination 5 (Chunk Size: 750, Overlap: 150, Retriever k: 3, LLM Tokens: 128, LLM Temp: 0.1)\n",
      "Response: Do not add personal opinions or experiences.\n",
      "\n",
      "The person with a fractured leg should receive initial treatment in the emergency department. Life-threatening injuries, such as hemorrhagic shock or arterial injuries, should be addressed first. For fractures, treatment may include splinting, definitive treatment (such as reduction), and RICE (rest, ice, compression, and elevation). Immobilization is usually necessary. Nerve conduction studies may be indicated for nerve injuries. For severe injuries, surgery may be required. Complications, such as rapid blood loss and fat embolism, should\n",
      "Groundedness Rating: 5\n",
      "The response is fully supported by the\n",
      "Relevance Rating: 5\n",
      "Context Preview: weakness are present.\n",
      "Treatment\n",
      "• Rest, ice, and compression\n",
      "• Stretching, then strengthening exercises\n",
      "Ice and compression with use of a thigh sleeve should begin as soon as possible. NSAIDs and anal...\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- Compare Results ---\n",
    "print(\"\\n\\n--- Comparison of Results ---\")\n",
    "for query_name, query_text in queries_to_test.items():\n",
    "    print(f\"\\n### {query_name}: {query_text}\")\n",
    "    for combo_name, query_results in results.items():\n",
    "        response_text = query_results.get(query_name, \"Response not found\")\n",
    "        eval_data = evaluation_results.get(combo_name, {}).get(query_name, {})\n",
    "        print(f\"\\n#### {combo_name} (Chunk Size: {param_combinations[int(combo_name.split(' ')[1])-1]['chunk_size']}, \"\n",
    "              f\"Overlap: {param_combinations[int(combo_name.split(' ')[1])-1]['chunk_overlap']}, \"\n",
    "              f\"Retriever k: {param_combinations[int(combo_name.split(' ')[1])-1]['retriever_k']}, \"\n",
    "              f\"LLM Tokens: {param_combinations[int(combo_name.split(' ')[1])-1]['llm_max_tokens']}, \"\n",
    "              f\"LLM Temp: {param_combinations[int(combo_name.split(' ')[1])-1]['llm_temperature']})\")\n",
    "        print(f\"Response: {response_text}\")\n",
    "        print(f\"Groundedness Rating: {eval_data.get('groundedness_rating', 'N/A')}\")\n",
    "        print(f\"Relevance Rating: {eval_data.get('relevance_rating', 'N/A')}\")\n",
    "        print(f\"Context Preview: {eval_data.get('context', 'N/A')}\")\n",
    "        print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluation Results Summary ---\n",
      "                                                            Groundedness  \\\n",
      "Combination 1 Query 1                    5\\nExplanation: The response is   \n",
      "              Query 2  5. The response accurately describes the commo...   \n",
      "              Query 3          5\\nThe response accurately identifies alo   \n",
      "              Query 4   5. The response accurately reflects the context,   \n",
      "              Query 5  5. The response accurately reflects the contex...   \n",
      "Combination 2 Query 1  5. The response accurately describes the proto...   \n",
      "              Query 2          5. All factual claims are fully supported   \n",
      "              Query 3          5. The response accurately identifies alo   \n",
      "              Query 4          5. The response is fully supported by the   \n",
      "              Query 5          5\\nAll factual claims are fully supported   \n",
      "Combination 3 Query 1                5\\nThe protocol for managing sepsis   \n",
      "              Query 2          5. All factual claims are fully supported   \n",
      "              Query 3          5\\nAll factual claims are fully supported   \n",
      "              Query 4          5\\nThe response is fully supported by the   \n",
      "              Query 5  5. The response accurately reflects the contex...   \n",
      "Combination 4 Query 1            5\\nExplanation: The response accurately   \n",
      "              Query 2          5\\nAll factual claims are fully supported   \n",
      "              Query 3          5. The response accurately identifies alo   \n",
      "              Query 4          5. The response is fully supported by the   \n",
      "              Query 5                  5\\nAll factual claims made in the   \n",
      "Combination 5 Query 1  5. The response accurately describes the proto...   \n",
      "              Query 2          5. All factual claims are fully supported   \n",
      "              Query 3          5. The response accurately identifies alo   \n",
      "              Query 4  5\\n\\nThe response accurately reflects the context   \n",
      "              Query 5          5\\nThe response is fully supported by the   \n",
      "\n",
      "                                                               Relevance  \n",
      "Combination 1 Query 1              5\\nExplanation: The response directly  \n",
      "              Query 2                                                  5  \n",
      "              Query 3                                                  5  \n",
      "              Query 4  5. The response directly addresses the questio...  \n",
      "              Query 5                                                  5  \n",
      "Combination 2 Query 1                                                  5  \n",
      "              Query 2                                                  5  \n",
      "              Query 3  5\\nThe response directly addresses the questio...  \n",
      "              Query 4                                                  5  \n",
      "              Query 5  5\\nThe response directly addresses the questio...  \n",
      "Combination 3 Query 1  5\\nThe response directly addresses the questio...  \n",
      "              Query 2                                                  5  \n",
      "              Query 3  5\\nThe response directly addresses the questio...  \n",
      "              Query 4                                                  5  \n",
      "              Query 5                                                  5  \n",
      "Combination 4 Query 1                                                  5  \n",
      "              Query 2  5\\nThe response directly addresses the questio...  \n",
      "              Query 3                                                  5  \n",
      "              Query 4                                                  5  \n",
      "              Query 5                                                  5  \n",
      "Combination 5 Query 1                                                  5  \n",
      "              Query 2                                                  5  \n",
      "              Query 3                                                  5  \n",
      "              Query 4  5\\nThe response directly addresses the questio...  \n",
      "              Query 5                                                  5  \n"
     ]
    }
   ],
   "source": [
    "# --- Evaluation Summary ---\n",
    "print(\"\\n--- Evaluation Results Summary ---\")\n",
    "eval_summary = {}\n",
    "for combo_name in evaluation_results:\n",
    "    eval_summary[combo_name] = {}\n",
    "    for query_name in queries_to_test:\n",
    "        eval_data = evaluation_results[combo_name].get(query_name, {})\n",
    "        eval_summary[combo_name][query_name] = {\n",
    "            \"Groundedness\": eval_data.get(\"groundedness_rating\", \"N/A\"),\n",
    "            \"Relevance\": eval_data.get(\"relevance_rating\", \"N/A\")\n",
    "        }\n",
    "eval_df = pd.DataFrame.from_dict({(c, q): eval_summary[c][q] for c in eval_summary for q in eval_summary[c]}, orient='index')\n",
    "print(eval_df)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "3CNz35ia6Bz3",
    "CkRbhMJH6Bz3",
    "CARPKFwm6Bz4",
    "by9EvAnkSpZf",
    "lnwETBOE6Bz5",
    "TtZWqj0wFTS1",
    "Uq1lhM4WFTS2",
    "EzzkvIXvFTS4",
    "K8YgK91SFjVY",
    "J6yxICeVFjVc",
    "oflaoOGiFjVd",
    "WUUqY4FbFjVe",
    "5laPFTHrFjVf",
    "g5myZ5dOOefc",
    "9Jg3r_LWOeff",
    "iYpyw4HjOeff",
    "dRp92JQZOeff",
    "AA45zwyUOefg",
    "TYXxiSuBOefg",
    "t_O1PGdNO2M9",
    "uTpWESc53dL9",
    "ffj0ca3eZT4u",
    "f9weTDzMxRRS",
    "7-wNNalNxPKT",
    "LECMxTH-zB-R",
    "BvHVejcWz0Bl",
    "qiKCOv4X0d7B",
    "uEa5sKc41T1z",
    "vw8qcwq66B0C",
    "TkIteX4m6mny",
    "ffP1SRYbPQHN",
    "JjajBEj06B0E",
    "QDw8zXuq6B0F",
    "TggYyQPL6B0G",
    "1TgxdI-_6B0G",
    "FlHXYCkm6B0H",
    "K7TYrqycEITB",
    "Y7QICRU-njdj"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0017b53b36ea4562aad1a3986d0605e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a9ab2158c9f548fb9a00742cc1aded21",
      "placeholder": "​",
      "style": "IPY_MODEL_bb697fbb85ee492997c47e28714db00c",
      "value": "config.json: 100%"
     }
    },
    "004dbb3b4dda406db8641b6df8b471dc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0132362cb7dc405087e4a4b92e5dbb49": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "01908b4c3692436bacc077e13b163da6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "01a50273972449dbbe1e9c9edf42a932": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "020d7d3934e04204aeb1bc66e64af1c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_de4021eb3df64971abff623e2affa9cd",
      "max": 349,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_812ca01252ee422693a1b5cf7852766c",
      "value": 349
     }
    },
    "0294b9bc5d2f44d09163237bcd68927d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_788a9ce6505f464bb05e798ada338ba4",
       "IPY_MODEL_61a73dac3e2147888ca65a4ceb023ec5",
       "IPY_MODEL_417783ced0c049acbf0d5a3fba5b2426"
      ],
      "layout": "IPY_MODEL_f2ccf0fdb9934c9e990b75ae27a729da"
     }
    },
    "05653f41b2d048db8c7a7311050e11f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_daf765af390c4057bae663e1346c0d0b",
      "max": 10454,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_73c85ac9767b4ce4bcee6561b0ef3009",
      "value": 10454
     }
    },
    "0e58e7e78c754bbe91262e710857b53d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "109692fe97f249f79a9316c788b97ff6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1101bbfbaf5c4abeba6f3746c54629dd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "12396dda069842029d289643b9be6083": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "132cb8ea082e405eaa869cda9cddbea6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_843a56ab833d44fe837055d3481e19e0",
      "placeholder": "​",
      "style": "IPY_MODEL_6492690370854073ba3e1ebdaf447202",
      "value": " 190/190 [00:00&lt;00:00, 19.3kB/s]"
     }
    },
    "162744977d884c41a3f4714154846321": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1a8cc165211c40f1bd0224c73c0741a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_366e54785395488ab011e88dd4431582",
       "IPY_MODEL_dde78db6b7314ed5b8bc855bfc3ee83b",
       "IPY_MODEL_441db1a0bab94ebc9a30f2959efcb19e"
      ],
      "layout": "IPY_MODEL_757ab35fcd6b437cbf2cd6f02f003c39"
     }
    },
    "1dc25300365d44a5a4edb1822f5fc487": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1dff4b40189b45278f9c91f42a3f0a1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1e7bf49c43dc41df8008ac5677ef1cea",
      "placeholder": "​",
      "style": "IPY_MODEL_22264af3652d460884cdb736a66afe20",
      "value": " 232k/232k [00:00&lt;00:00, 540kB/s]"
     }
    },
    "1e7bf49c43dc41df8008ac5677ef1cea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e9043cd78b74228b3b17bfa00f6fd0a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "22264af3652d460884cdb736a66afe20": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "246a978f6fe44570992457c8d3288992": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "256ac56e2bb84eddb5f64a2008bf1bd2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "25dfc1e7813c443b9e16750b91585366": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "27c2411bbaa545978b4363a294f87cd7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "294dcd8c75074479a6858054eab2d540": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2962d6b1aafd4d2cb8b6115d2686c761": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_109692fe97f249f79a9316c788b97ff6",
      "max": 112,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4c9446a082824171a0d64116b6a2fb4d",
      "value": 112
     }
    },
    "2abd44767b5a41fdab727f5194423a55": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "2b91f962e8ef4a089c0e55a4652d6efa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_246a978f6fe44570992457c8d3288992",
      "placeholder": "​",
      "style": "IPY_MODEL_728613c663a4414ab0d37d66dfadbf56",
      "value": "README.md: 100%"
     }
    },
    "2ccf33261e8244aaa78f35de441fe3a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "302a1d59b3e6486ea8192e89501167a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_53b82a55a85c46c3831585ab623639ec",
      "placeholder": "​",
      "style": "IPY_MODEL_162744977d884c41a3f4714154846321",
      "value": "vocab.txt: 100%"
     }
    },
    "36590b88aaab41b3be490cb271fce656": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_69b8ce2175dd410eb32938bd49571a97",
      "placeholder": "​",
      "style": "IPY_MODEL_de273ed51a9940f3ad99ec8973d1942b",
      "value": " 112/112 [00:00&lt;00:00, 10.5kB/s]"
     }
    },
    "366e54785395488ab011e88dd4431582": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c967eebc0e9a4fb389298b2dbea5cc27",
      "placeholder": "​",
      "style": "IPY_MODEL_fc22e13681bb41f58a7610e24ab0ecb0",
      "value": "model.safetensors: 100%"
     }
    },
    "3ae17e81478c470795ab369862d4c1f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3fdddaf6266d4fd3baa601665a13355f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "411fb81621fb404683ee1b0e8f90103b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "417783ced0c049acbf0d5a3fba5b2426": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9190decfac64415eb455a427e4a0fbfe",
      "placeholder": "​",
      "style": "IPY_MODEL_6b4f09ded6614a34ad8cb3a43c8bedaa",
      "value": " 0/0 [00:00&lt;?, ?it/s]"
     }
    },
    "41a512e0cbbc4260a8903dfcfe5c7a74": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "439bf2f56ddf4923b00c7a9b068c44db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_63b36345134e4d67b1f7c32c7d248c46",
      "placeholder": "​",
      "style": "IPY_MODEL_4d54d26b51e3441bbbd42604afcc174f",
      "value": " 53.0/53.0 [00:00&lt;00:00, 5.43kB/s]"
     }
    },
    "441db1a0bab94ebc9a30f2959efcb19e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0132362cb7dc405087e4a4b92e5dbb49",
      "placeholder": "​",
      "style": "IPY_MODEL_60a53f485e254dad93537e40d1a2052e",
      "value": " 90.9M/90.9M [00:02&lt;00:00, 35.4MB/s]"
     }
    },
    "491063168b6c4e99b7c2d4a13f09431f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4b712678d0254057b58ed3303bad94f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f66c5e89116a40f2aa04bed4adefb6d1",
       "IPY_MODEL_543b93c3e984433d8bab0213b9a77f87",
       "IPY_MODEL_7860d48fb9f44452a9e78537b853bd8e"
      ],
      "layout": "IPY_MODEL_b6eb29a5b76e45b38a0ce826598cdd07"
     }
    },
    "4b98af2c3ab84907aeee173081a75163": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4c4d0a3d6c9740edb9e9da5646ddc174": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4c9446a082824171a0d64116b6a2fb4d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4d54d26b51e3441bbbd42604afcc174f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "50946886cf864c698d31f47513c0e9b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "53b82a55a85c46c3831585ab623639ec": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "543b93c3e984433d8bab0213b9a77f87": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_004dbb3b4dda406db8641b6df8b471dc",
      "max": 116,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4c4d0a3d6c9740edb9e9da5646ddc174",
      "value": 116
     }
    },
    "5753f716481847d1bd5df05bbde1f46b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "57c511de322f4dd1a38885960ab3c9cf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "599b7be55846425abd3dc269df142ab0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_302a1d59b3e6486ea8192e89501167a7",
       "IPY_MODEL_db05e703900c413ab323686dcf90d658",
       "IPY_MODEL_1dff4b40189b45278f9c91f42a3f0a1b"
      ],
      "layout": "IPY_MODEL_cb3500b9269c4cbfb7982af16946cca9"
     }
    },
    "5d399db616df4f15a6659a76fb4bf5b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5f04c98085cc452d8d2b261607ff245e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "60a53f485e254dad93537e40d1a2052e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6138dd2be99746a0a95677aeb2f378c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b0c7d04668aa468e8e14fcc34059f461",
      "max": 466247,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_256ac56e2bb84eddb5f64a2008bf1bd2",
      "value": 466247
     }
    },
    "61a73dac3e2147888ca65a4ceb023ec5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2abd44767b5a41fdab727f5194423a55",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d7ef6d4469dc473f868d2bad3aab4828",
      "value": 0
     }
    },
    "63b36345134e4d67b1f7c32c7d248c46": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6492690370854073ba3e1ebdaf447202": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "671fe2339a454f7087ad5486708d27ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c6d9415461894735968b730dc1049797",
      "placeholder": "​",
      "style": "IPY_MODEL_5f04c98085cc452d8d2b261607ff245e",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "6882573750dc4b2bbb8dbd0b7f15649e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "69b8ce2175dd410eb32938bd49571a97": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6a0fc1d3ebc444b8ba5a3de02e06b3d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_84dc01a7b87242a39c2e24383570e1ed",
      "placeholder": "​",
      "style": "IPY_MODEL_5d399db616df4f15a6659a76fb4bf5b3",
      "value": " 349/349 [00:00&lt;00:00, 35.1kB/s]"
     }
    },
    "6b4f09ded6614a34ad8cb3a43c8bedaa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "728613c663a4414ab0d37d66dfadbf56": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "73c85ac9767b4ce4bcee6561b0ef3009": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "73f3ee296b6349d2ac0d490a907822ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2b91f962e8ef4a089c0e55a4652d6efa",
       "IPY_MODEL_05653f41b2d048db8c7a7311050e11f4",
       "IPY_MODEL_a61c1bc8a7c541248394d1c83240e070"
      ],
      "layout": "IPY_MODEL_01908b4c3692436bacc077e13b163da6"
     }
    },
    "757ab35fcd6b437cbf2cd6f02f003c39": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "783b19f002d74710871eb992a6cba58a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7860d48fb9f44452a9e78537b853bd8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_294dcd8c75074479a6858054eab2d540",
      "placeholder": "​",
      "style": "IPY_MODEL_3ae17e81478c470795ab369862d4c1f7",
      "value": " 116/116 [00:00&lt;00:00, 10.7kB/s]"
     }
    },
    "788a9ce6505f464bb05e798ada338ba4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1101bbfbaf5c4abeba6f3746c54629dd",
      "placeholder": "​",
      "style": "IPY_MODEL_27c2411bbaa545978b4363a294f87cd7",
      "value": ""
     }
    },
    "79ed3c283a8d49618283c433f3896d56": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7d9b17e532ff40aba1bc293461e7deda": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7e9388ed5baf45ae805655ab2f3eb7a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_783b19f002d74710871eb992a6cba58a",
      "placeholder": "​",
      "style": "IPY_MODEL_491063168b6c4e99b7c2d4a13f09431f",
      "value": " 612/612 [00:00&lt;00:00, 67.7kB/s]"
     }
    },
    "7f9a8443a0a64b0285010e123eb3b41e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3fdddaf6266d4fd3baa601665a13355f",
      "placeholder": "​",
      "style": "IPY_MODEL_8c78f0b438774217bc1ec91b117bfb58",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "812ca01252ee422693a1b5cf7852766c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "843a56ab833d44fe837055d3481e19e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "84dc01a7b87242a39c2e24383570e1ed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "874caf49704a49b7ad1bed017d579c6d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e4481fe3f2f44a35934c9d6aced94941",
       "IPY_MODEL_020d7d3934e04204aeb1bc66e64af1c7",
       "IPY_MODEL_6a0fc1d3ebc444b8ba5a3de02e06b3d2"
      ],
      "layout": "IPY_MODEL_57c511de322f4dd1a38885960ab3c9cf"
     }
    },
    "899930cfaee14f4da69bfe5d44eab72e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f2cb49e40f6c4e8f85ecc983331188cf",
      "placeholder": "​",
      "style": "IPY_MODEL_8d50f31db1c240abafd583b597e73543",
      "value": " 466k/466k [00:00&lt;00:00, 2.76MB/s]"
     }
    },
    "8c78f0b438774217bc1ec91b117bfb58": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8cd8f1285bb946da8dc29be6ce10cca0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8d50f31db1c240abafd583b597e73543": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8e0cbb347c8f4fd6a642b19318dfebfa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9190decfac64415eb455a427e4a0fbfe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "984bea400e154cfb9acf6f88b4ae064c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9994eed521c24fbe84f48663733df80b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a3917dfe70f94e61b8ea2e6b09c07b6b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d96c01d2188240c697f78ef58a421e93",
      "placeholder": "​",
      "style": "IPY_MODEL_b8c7104ed50343369e1db39279f630d3",
      "value": " 350/350 [00:00&lt;00:00, 30.2kB/s]"
     }
    },
    "a61c1bc8a7c541248394d1c83240e070": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f3b966510aa7461dad137335cffe8c39",
      "placeholder": "​",
      "style": "IPY_MODEL_984bea400e154cfb9acf6f88b4ae064c",
      "value": " 10.5k/10.5k [00:00&lt;00:00, 720kB/s]"
     }
    },
    "a870c0b063a3464f9b9c9be43451ba55": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a8c95e5e504146db9f57a1eab47cdbfb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bf7c4b3ad8a449a7a66cd6873c197357",
       "IPY_MODEL_dcf39f054da348469f662529b51a6c3f",
       "IPY_MODEL_7e9388ed5baf45ae805655ab2f3eb7a3"
      ],
      "layout": "IPY_MODEL_41a512e0cbbc4260a8903dfcfe5c7a74"
     }
    },
    "a9ab2158c9f548fb9a00742cc1aded21": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ac9082833f5548f9b63b2976930f58db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_25dfc1e7813c443b9e16750b91585366",
      "max": 190,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b4bf43b475f44f698136985ab12dd7a4",
      "value": 190
     }
    },
    "b0c7d04668aa468e8e14fcc34059f461": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b1276ee2c3a449dcabc367beababb108": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b24897dcb9454fdab7a376b41915530f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b4bf43b475f44f698136985ab12dd7a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b5c670793eec4695af26fdb6275d1255": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_671fe2339a454f7087ad5486708d27ef",
       "IPY_MODEL_eac2627aaf5d4efa9700de758f0b7f78",
       "IPY_MODEL_a3917dfe70f94e61b8ea2e6b09c07b6b"
      ],
      "layout": "IPY_MODEL_5753f716481847d1bd5df05bbde1f46b"
     }
    },
    "b6eb29a5b76e45b38a0ce826598cdd07": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b8c7104ed50343369e1db39279f630d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b9bd8d1f8df14fdba410c0a43f1e48ba": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bb24a64ad998447390ebe96ec953b2a3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bb697fbb85ee492997c47e28714db00c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bf7c4b3ad8a449a7a66cd6873c197357": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b1276ee2c3a449dcabc367beababb108",
      "placeholder": "​",
      "style": "IPY_MODEL_79ed3c283a8d49618283c433f3896d56",
      "value": "config.json: 100%"
     }
    },
    "bfcf8d7839bb4d0ebcfc635ac8220733": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c66b7e7e8e6a464e8d8e99023dcb4014": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b9bd8d1f8df14fdba410c0a43f1e48ba",
      "max": 53,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6882573750dc4b2bbb8dbd0b7f15649e",
      "value": 53
     }
    },
    "c6d9415461894735968b730dc1049797": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c756b5b005bf46adb9386746aeabde75": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7f9a8443a0a64b0285010e123eb3b41e",
       "IPY_MODEL_2962d6b1aafd4d2cb8b6115d2686c761",
       "IPY_MODEL_36590b88aaab41b3be490cb271fce656"
      ],
      "layout": "IPY_MODEL_411fb81621fb404683ee1b0e8f90103b"
     }
    },
    "c967eebc0e9a4fb389298b2dbea5cc27": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb3500b9269c4cbfb7982af16946cca9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ceaee8123699400a8fccaedca33de802": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cfb5f51567134988abc49f443ae22b42": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d7ef6d4469dc473f868d2bad3aab4828": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d96c01d2188240c697f78ef58a421e93": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "daf765af390c4057bae663e1346c0d0b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "db05e703900c413ab323686dcf90d658": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0e58e7e78c754bbe91262e710857b53d",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2ccf33261e8244aaa78f35de441fe3a5",
      "value": 231508
     }
    },
    "dc4b08518d19436d8d2238afc5d439ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ceaee8123699400a8fccaedca33de802",
      "placeholder": "​",
      "style": "IPY_MODEL_1e9043cd78b74228b3b17bfa00f6fd0a",
      "value": "tokenizer.json: 100%"
     }
    },
    "dcf39f054da348469f662529b51a6c3f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7d9b17e532ff40aba1bc293461e7deda",
      "max": 612,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4b98af2c3ab84907aeee173081a75163",
      "value": 612
     }
    },
    "dde78db6b7314ed5b8bc855bfc3ee83b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bb24a64ad998447390ebe96ec953b2a3",
      "max": 90868376,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bfcf8d7839bb4d0ebcfc635ac8220733",
      "value": 90868376
     }
    },
    "de273ed51a9940f3ad99ec8973d1942b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "de4021eb3df64971abff623e2affa9cd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e4481fe3f2f44a35934c9d6aced94941": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_12396dda069842029d289643b9be6083",
      "placeholder": "​",
      "style": "IPY_MODEL_1dc25300365d44a5a4edb1822f5fc487",
      "value": "modules.json: 100%"
     }
    },
    "e46496cd547c4d07b20b3589a53a7ae7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ee32c8a02f32487f90f46aa4f24cd88d",
       "IPY_MODEL_c66b7e7e8e6a464e8d8e99023dcb4014",
       "IPY_MODEL_439bf2f56ddf4923b00c7a9b068c44db"
      ],
      "layout": "IPY_MODEL_cfb5f51567134988abc49f443ae22b42"
     }
    },
    "e67638db8e2a467f92daead399145650": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eac2627aaf5d4efa9700de758f0b7f78": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8e0cbb347c8f4fd6a642b19318dfebfa",
      "max": 350,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a870c0b063a3464f9b9c9be43451ba55",
      "value": 350
     }
    },
    "ee32c8a02f32487f90f46aa4f24cd88d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b24897dcb9454fdab7a376b41915530f",
      "placeholder": "​",
      "style": "IPY_MODEL_01a50273972449dbbe1e9c9edf42a932",
      "value": "sentence_bert_config.json: 100%"
     }
    },
    "f2cb49e40f6c4e8f85ecc983331188cf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f2ccf0fdb9934c9e990b75ae27a729da": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f3b966510aa7461dad137335cffe8c39": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f66c5e89116a40f2aa04bed4adefb6d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e67638db8e2a467f92daead399145650",
      "placeholder": "​",
      "style": "IPY_MODEL_50946886cf864c698d31f47513c0e9b6",
      "value": "config_sentence_transformers.json: 100%"
     }
    },
    "f786eda4a6a14ebd9f58ed2ce1c8c986": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_dc4b08518d19436d8d2238afc5d439ec",
       "IPY_MODEL_6138dd2be99746a0a95677aeb2f378c8",
       "IPY_MODEL_899930cfaee14f4da69bfe5d44eab72e"
      ],
      "layout": "IPY_MODEL_8cd8f1285bb946da8dc29be6ce10cca0"
     }
    },
    "fc22e13681bb41f58a7610e24ab0ecb0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fd36eedfcc524d0ab474c615a9c9b1d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0017b53b36ea4562aad1a3986d0605e2",
       "IPY_MODEL_ac9082833f5548f9b63b2976930f58db",
       "IPY_MODEL_132cb8ea082e405eaa869cda9cddbea6"
      ],
      "layout": "IPY_MODEL_9994eed521c24fbe84f48663733df80b"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
